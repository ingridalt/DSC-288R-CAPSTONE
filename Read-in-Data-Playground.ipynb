{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06b4a184-06bb-4a6e-b440-9f5599610b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting duckdb\n",
      "  Downloading duckdb-1.4.3-cp311-cp311-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (2.31.0)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading duckdb-1.4.3-cp311-cp311-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (20.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: duckdb\n",
      "Successfully installed duckdb-1.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install duckdb pandas requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e57b035c-acb2-44f9-83ac-319b9279b3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: duckdb in /home/ialtamir/.local/lib/python3.11/site-packages (1.4.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install duckdb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceecbcfe-cd36-48a1-b4df-b016245e706d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#Here we can try differnt years but i think the latest is 2024 ia to check and honestlly based on problem statement \n",
    "def download_pums_file(state_abbr, record_type, year=\"2023\"):\n",
    "    \"\"\"\n",
    "    record_type: 'p' for person, 'h' for housing\n",
    "    \"\"\"\n",
    "    url = f\"https://www2.census.gov/programs-surveys/acs/data/pums/{year}/5-Year/csv_{record_type}{state_abbr}.zip\"\n",
    "    dest_folder = f\"data_{state_abbr}\"\n",
    "    os.makedirs(dest_folder, exist_ok=True)\n",
    "    \n",
    "    print(f\"Downloading {record_type} records for {state_abbr}...\")\n",
    "    response = requests.get(url, stream=True)\n",
    "    \n",
    "    with zipfile.ZipFile(io.BytesIO(response.content)) as z:\n",
    "        z.extractall(dest_folder)\n",
    "        print(f\"Extracted to {dest_folder}\")\n",
    "\n",
    "# Download  California we only want to do once really \n",
    "#download_pums_file(\"ca\", \"p\")\n",
    "#download_pums_file(\"ca\", \"h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b6d054-95f3-4961-9c75-112275b2b4a7",
   "metadata": {},
   "source": [
    "## Housing Specifically "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7caf503b-3f02-4f84-966c-f2ce6d463c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Housing Variables (96): ['RT', 'SERIALNO', 'DIVISION', 'PUMA', 'REGION', 'STATE', 'ADJHSG', 'ADJINC', 'NP', 'TYPEHUGQ', 'ACCESSINET', 'ACR', 'AGS', 'BATH', 'BDSP', 'BLD', 'BROADBND', 'COMPOTHX', 'CONP', 'DIALUP', 'ELEFP', 'ELEP', 'GASFP', 'GASP', 'HFL', 'HISPEED', 'HOTWAT', 'INSP', 'LAPTOP', 'MHP', 'MRGI', 'MRGP', 'MRGT', 'MRGX', 'OTHSVCEX', 'REFR', 'RMSP', 'RNTM', 'RNTP', 'RWAT', 'RWATPR', 'SATELLITE', 'SINK', 'SMARTPHONE', 'SMP', 'STOV', 'TABLET', 'TEL', 'TEN', 'VACS', 'VALP', 'VEH', 'WATFP', 'WATP', 'YRBLT', 'CPLT', 'GRNTP', 'GRPIP', 'HHL', 'HHLANP', 'HHLDRAGEP', 'HHLDRHISP', 'HHLDRRAC1P', 'HHT', 'HHT2', 'HINCP', 'HUGCL', 'HUPAC', 'HUPAOC', 'HUPARC', 'KIT', 'LNGI', 'MULTG', 'MV', 'NOC', 'NPF', 'NPP', 'NR', 'NRC', 'OCPIP', 'PARTNER', 'PLM', 'PLMPRP', 'PSF', 'R18', 'R60', 'R65', 'RESMODE', 'SMOCP', 'SMX', 'SRNT', 'SVAL', 'TAXAMT', 'WIF', 'WKEXREL', 'WORKSTAT']\n"
     ]
    }
   ],
   "source": [
    "clean_housing_cols = [c for c in housing_headers if not c.startswith('WGTP') and not c.startswith('F')]\n",
    "print(f\"Cleaned Housing Variables ({len(clean_housing)}):\", clean_housing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c0321d8-ba22-4552-a523-374876f9a234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of Housing Variables are: 237\n",
      "The length of Person Variables are: 286\n"
     ]
    }
   ],
   "source": [
    "all_headers_housing = pd.read_csv('data_ca/psam_h06.csv', nrows=0).columns.tolist()\n",
    "print(f\"The length of Housing Variables are: {len(all_headers_housing)}\")\n",
    "\n",
    "clean_housing_cols = [c for c in all_headers if not c.startswith('WGTP') and not c.startswith('F')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66bae704-f1c4-4f7a-9f3e-b553ec2bb04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RT       SERIALNO  DIVISION   PUMA  REGION STATE   ADJHSG   ADJINC  NP  \\\n",
      "0  H  2019GQ0000003         9  03704       4    06  1195583  1207712   1   \n",
      "1  H  2019GQ0000009         9  07322       4    06  1195583  1207712   1   \n",
      "2  H  2019GQ0000013         9  05923       4    06  1195583  1207712   1   \n",
      "3  H  2019GQ0000023         9  07107       4    06  1195583  1207712   1   \n",
      "4  H  2019GQ0000024         9  08900       4    06  1195583  1207712   1   \n",
      "5  H  2019GQ0000048         9  03770       4    06  1195583  1207712   1   \n",
      "6  H  2019GQ0000055         9  11107       4    06  1195583  1207712   1   \n",
      "7  H  2019GQ0000064         9  03703       4    06  1195583  1207712   1   \n",
      "8  H  2019GQ0000070         9  11104       4    06  1195583  1207712   1   \n",
      "9  H  2019GQ0000074         9  02906       4    06  1195583  1207712   1   \n",
      "\n",
      "   TYPEHUGQ  \n",
      "0         3  \n",
      "1         2  \n",
      "2         3  \n",
      "3         2  \n",
      "4         3  \n",
      "5         2  \n",
      "6         3  \n",
      "7         2  \n",
      "8         3  \n",
      "9         2  \n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "\n",
    "# Connect and view the first 5 rows of specific columns\n",
    "con = duckdb.connect()\n",
    "sample_query = f\"SELECT {', '.join(clean_cols[:10])} FROM 'data_ca/psam_h06.csv' LIMIT 10\"\n",
    "print(con.execute(sample_query).df())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b84d45d7-6551-4ecc-aeba-d7049b4cb22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      0\n",
      "RT                    H\n",
      "SERIALNO  2019GQ0000003\n",
      "DIVISION              9\n",
      "PUMA              03704\n",
      "REGION                4\n",
      "...                 ...\n",
      "WGTP76                0\n",
      "WGTP77                0\n",
      "WGTP78                0\n",
      "WGTP79                0\n",
      "WGTP80                0\n",
      "\n",
      "[237 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "full_row_check = con.execute(\"SELECT * FROM 'data_ca/psam_h06.csv' LIMIT 1\").df().T\n",
    "\n",
    "print(full_row_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df86e7f-cfcf-4dee-9dea-6099afa77145",
   "metadata": {},
   "source": [
    "## Persons Specifically "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e76c7a41-a370-4be5-b648-bf7f1c1f1c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of Person Variables are: 286\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "all_headers_persons = pd.read_csv('data_ca/psam_p06.csv', nrows=0).columns.tolist()\n",
    "print(f\"The length of Person Variables are: {len(all_headers_persons)}\")\n",
    "clean_persons_cols = [c for c in all_headers_persons if not c.startswith('WGTP') and not c.startswith('F')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce0eb0a-a549-41ff-9306-ebbf2f5453ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "090a4959-6b86-46ad-a11c-8cdd3f6959f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257K\tdata_ca/.ipynb_checkpoints\n",
      "788M\tdata_ca/\n"
     ]
    }
   ],
   "source": [
    "!du -h data_ca/ | sort -h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d37a69-a382-45c9-b324-8820e9a73ecd",
   "metadata": {},
   "source": [
    "### I guess we can think about the actual architecture or ways of manipulating the file \n",
    "\n",
    "import duckdb\n",
    "\n",
    "#  connection to a local DuckDB file (this acts as  storage)\n",
    "con = duckdb.connect('acs_california_2023.db')\n",
    "\n",
    "#  Register the CSVs as virtual tablesm ??? (without loading them into RAM)\n",
    "\n",
    "con.execute(\"\"\"\n",
    "    CREATE TABLE person_raw AS SELECT * FROM read_csv_auto('data_ca/psam_p06.csv');\n",
    "    CREATE TABLE housing_raw AS SELECT * FROM read_csv_auto('data_ca/psam_h06.csv');\n",
    "\"\"\")\n",
    "\n",
    "# 2. Join  and select only the columns needed, here we must figure out what we acually want to use ... to keep table small\n",
    "con.execute(\"\"\"\n",
    "    CREATE TABLE ml_ready_data AS \n",
    "    SELECT \n",
    "        p.SERIALNO, \n",
    "        p.AGEP, \n",
    "        p.SEX, \n",
    "        p.SCHL, \n",
    "        p.ESR, -- Employment status\n",
    "        h.HINCP, -- Household Income\n",
    "        h.NP,    -- Number of persons in household\n",
    "        h.VEH    -- Number of vehicles\n",
    "    FROM person_raw p\n",
    "    JOIN housing_raw h ON p.SERIALNO = h.SERIALNO\n",
    "\"\"\")\n",
    "\n",
    "print(con.execute(\"SELECT count(*) FROM ml_ready_data\").fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43f5ea7-2bfd-49f9-aa1d-d85fd9d5bd67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
