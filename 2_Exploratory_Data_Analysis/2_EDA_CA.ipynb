{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48b1386c-a737-48f2-9891-bcdba9d3b84a",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis - California ACS Person Data\n",
    "\n",
    "This notebook performs EDA."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pwd",
   "id": "8320074b1d5d92a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ec8a51cb-8887-42ea-a06b-4c7873c972cf",
   "metadata": {},
   "source": [
    "#these column names don't mean very much to us right now \n",
    "##we will a look at variables by mapping encoded column names to label\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "p_file = \"../1_Raw_Data/data_persons_ca_1yr/persons_master.csv\"\n",
    "all_headers_persons = pd.read_csv(p_file, nrows=0).columns.tolist()\n",
    "\n",
    "print(\"Number of columns:\", len(all_headers_persons))\n",
    "print(\"First 20 columns:\", all_headers_persons[:20])\n",
    "print(\"Last 10 columns:\", all_headers_persons[-10:])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "061a7c45-6b26-41df-91e6-8e178723525e",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# 1) get column names\n",
    "p_file = \"../1_Raw_Data/data_persons_ca_1yr/persons_master.csv\"\n",
    "cols = pd.read_csv(p_file, nrows=0).columns.tolist()\n",
    "\n",
    "print(\"Columns in file:\", len(cols))\n",
    "print(\"Example columns:\", cols[:12])\n",
    "\n",
    "# 2) fetch Census metadata dictionary\n",
    "url = \"https://api.census.gov/data/2023/acs/acs5/pums/variables.json\"\n",
    "meta = requests.get(url)\n",
    "meta.raise_for_status()\n",
    "vardict = meta.json()[\"variables\"]\n",
    "\n",
    "# 3) map each column -> explanation\n",
    "rows = []\n",
    "for c in cols:\n",
    "    info = vardict.get(c, {})\n",
    "    values_obj = info.get(\"values\")\n",
    "    rows.append({\n",
    "        \"column\": c,\n",
    "        \"label\": info.get(\"label\"),\n",
    "        \"predicateType\": info.get(\"predicateType\"),\n",
    "        \"values_json\": json.dumps(values_obj) if values_obj is not None else None\n",
    "    })\n",
    "\n",
    "df_dict = pd.DataFrame(rows)\n",
    "\n",
    "# 5) save\n",
    "df_dict.to_csv(\"EDA_data/all_pums_person_ca_data_dictionary.csv\", index=False)\n",
    "df_dict.head(20)\n",
    "\n",
    "#see the full result of columns mapped to label (column explanation) in EDA_data/all_pums_person_us_data_dictionary.csv"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "47bd70e9-dfd2-4092-93bc-3f17e09fae6c",
   "metadata": {},
   "source": [
    "# as you can see from EDA_data/all_pums_person_us_data_dictionary.csv, not all of these columns are useful\n",
    "## for example, columns that start with F are all allocation flags i.e. missing information inferred using stat methods\n",
    "### all columns that start with PWG are person weights are used to produce population estimates from sample data\n",
    "### we don't need these \n",
    "\n",
    "## dropping useless columns\n",
    "\n",
    "def is_useless(col):\n",
    "    if col.startswith(\"PWG\"):      # person weights + replicates\n",
    "        return True\n",
    "    if col.startswith(\"F\"):        # allocation flags\n",
    "        return True\n",
    "    if col in [\"RT\", \"SERIALNO\", \"SPORDER\"]:  # pure identifiers\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "df_clean = df_dict.loc[~df_dict[\"column\"].apply(is_useless)].copy()\n",
    "\n",
    "print(\"Clean dictionary shape:\", df_clean.shape)\n",
    "df_clean.head()\n",
    "\n",
    "df_clean.to_csv(\n",
    "    \"EDA_data/suggested_clean_data_dictionary.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(\"Saved: suggested_clean_data_dictionary.csv\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "efd4de2e-c61a-4759-ba57-94ff6ec84f9b",
   "metadata": {},
   "source": [
    "## 118 variables is still too many, lets try to cut it down further\n",
    "# lets try to remove: columns with too many null values, columns of variables that measure the same concept at different resolutions etc. \n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"EDA_data/suggested_clean_data_dictionary.csv\"\n",
    ")\n",
    "\n",
    "print(\"Starting columns:\", df.shape[0])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5b6e9b0a-ae0c-4850-b06b-db4e1f130ca5",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "dict_path = \"EDA_data/suggested_clean_data_dictionary.csv\"\n",
    "df_dict = pd.read_csv(dict_path)\n",
    "\n",
    "candidate_cols = df_dict[\"column\"].tolist()\n",
    "print(\"Number of candidate columns:\", len(candidate_cols))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "34fd99d2-1b09-4fc9-a5f4-5ecd048a44a3",
   "metadata": {},
   "source": [
    "p_file = \"../1_Raw_Data/data_persons_ca_1yr/psam_p06_master.csv\"\n",
    "\n",
    "df = pd.read_csv(\n",
    "    p_file,\n",
    "    usecols=candidate_cols\n",
    ")\n",
    "\n",
    "print(\"Shape of loaded data:\", df.shape)\n",
    "\n",
    "null_summary = (\n",
    "    df.isna()\n",
    "      .sum()\n",
    "      .reset_index()\n",
    "      .rename(columns={\"index\": \"column\", 0: \"n_null\"})\n",
    ")\n",
    "\n",
    "null_summary[\"pct_null\"] = null_summary[\"n_null\"] / len(df)\n",
    "\n",
    "null_summary = null_summary.sort_values(\"pct_null\", ascending=False)\n",
    "\n",
    "# load dictionary if not already loaded\n",
    "df_dict = pd.read_csv(\n",
    "    \"EDA_data/suggested_clean_data_dictionary.csv\"\n",
    ")\n",
    "\n",
    "# keep only what we need\n",
    "labels = df_dict[[\"column\", \"label\"]]\n",
    "\n",
    "# merge labels into null summary\n",
    "null_summary = null_summary.merge(\n",
    "    labels,\n",
    "    on=\"column\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# reorder columns for readability\n",
    "null_summary = null_summary[\n",
    "    [\"column\", \"label\", \"n_null\", \"pct_null\"]\n",
    "]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "68bc2657-6867-4638-b64c-c73f076fbb3a",
   "metadata": {},
   "source": [
    "null_summary.head(60)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "560a0510-cae8-47a0-a06b-eba5ee99c4cc",
   "metadata": {},
   "source": [
    "# lets drop any columns that have over 60% null values \n",
    "\n",
    "HIGH_NULL_CUTOFF = 0.60\n",
    "\n",
    "# 1) Load your current clean dictionary (the 123-col list)\n",
    "df_dict = pd.read_csv(dict_path)\n",
    "candidate_cols = df_dict[\"column\"].tolist()\n",
    "\n",
    "# 2) Load ONLY those columns from the person CSV\n",
    "df = pd.read_csv(p_file, usecols=candidate_cols)\n",
    "\n",
    "# 3) Compute null rates\n",
    "null_summary = (\n",
    "    df.isna()\n",
    "      .sum()\n",
    "      .reset_index()\n",
    "      .rename(columns={\"index\": \"column\", 0: \"n_null\"})\n",
    ")\n",
    "null_summary[\"pct_null\"] = null_summary[\"n_null\"] / len(df)\n",
    "\n",
    "# 4) Identify high-null columns to drop\n",
    "high_null_cols = null_summary.loc[\n",
    "    null_summary[\"pct_null\"] >= HIGH_NULL_CUTOFF,\n",
    "    \"column\"\n",
    "].tolist()\n",
    "\n",
    "print(f\"Columns in dict before: {len(candidate_cols)}\")\n",
    "print(f\"Dropping (pct_null >= {HIGH_NULL_CUTOFF}): {len(high_null_cols)}\")\n",
    "print(\"Dropped columns:\", high_null_cols)\n",
    "\n",
    "# 5) Prune dictionary and overwrite the same file\n",
    "df_dict_pruned = df_dict.loc[~df_dict[\"column\"].isin(high_null_cols)].copy()\n",
    "df_dict_pruned.to_csv(dict_path, index=False)\n",
    "\n",
    "print(f\"Columns in dict after: {df_dict_pruned.shape[0]}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ac9b4daf-20e2-4815-84ff-d0524d023ee5",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure POVPIP is numeric and drop missing values for exploration\n",
    "povpip = pd.to_numeric(df[\"POVPIP\"], errors=\"coerce\").dropna()\n",
    "\n",
    "# Basic summary statistics\n",
    "povpip.describe()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "13419020-eed0-4be5-8f1f-ea26f73d2b22",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3e898d84-821e-44fd-8b68-fa77edb7b5a0",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ad30c211-bfe1-4d2b-acda-15e258bfa509",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a3d6e06d-c4d5-4995-a729-f8c77a144236",
   "metadata": {},
   "source": [
    "## Target Variable Analysis (POVPIP)\n",
    "\n",
    "POVPIP is the income-to-poverty ratio recode:\n",
    "- Values 0-100: Below poverty threshold (100 = exactly at poverty line)\n",
    "- Values 101-500: Above poverty threshold (up to 5x poverty line)\n",
    "- Value 501: 501% or more of poverty threshold (capped)\n",
    "\n",
    "For our **multiclass classification** task, we define 4 poverty levels based on POVPIP:\n",
    "- **Deep Poverty** (0-50): Severe economic hardship, less than half the poverty threshold\n",
    "- **Poverty** (51-100): Below poverty line\n",
    "- **Near Poverty** (101-200): Above poverty line but vulnerable, low financial buffer\n",
    "- **Stable** (201+): More than twice the poverty threshold, relatively secure"
   ]
  },
  {
   "cell_type": "code",
   "id": "hy6fv1fj2jt",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Set style for visualizations\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Load data\n",
    "p_file = \"../1_Raw_Data/data_persons_ca_1yr/psam_p06_master.csv\"\n",
    "dict_path = \"EDA_data/suggested_clean_data_dictionary.csv\"\n",
    "\n",
    "df_dict = pd.read_csv(dict_path)\n",
    "candidate_cols = df_dict[\"column\"].tolist()\n",
    "\n",
    "print(f\"Loading {len(candidate_cols)} columns...\")\n",
    "df = pd.read_csv(p_file, usecols=candidate_cols)\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "print(f\"Total records: {len(df):,}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "hr4dnrjvbal",
   "metadata": {},
   "source": [
    "# POVPIP Distribution Analysis\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# 1. Raw POVPIP histogram with class boundaries\n",
    "povpip = df[\"POVPIP\"].dropna()\n",
    "axes[0].hist(povpip, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(x=50, color='darkred', linestyle='--', linewidth=2, label='Deep poverty (50)')\n",
    "axes[0].axvline(x=100, color='red', linestyle='--', linewidth=2, label='Poverty line (100)')\n",
    "axes[0].axvline(x=200, color='orange', linestyle='--', linewidth=2, label='Near poverty (200)')\n",
    "axes[0].set_xlabel('POVPIP (Income-to-Poverty Ratio %)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Distribution of POVPIP')\n",
    "axes[0].legend(fontsize=8)\n",
    "\n",
    "# 2. Zoomed in view (0-250) with class boundaries\n",
    "axes[1].hist(povpip[povpip <= 250], bins=50, edgecolor='black', alpha=0.7, color='orange')\n",
    "axes[1].axvline(x=50, color='darkred', linestyle='--', linewidth=2, label='Deep poverty')\n",
    "axes[1].axvline(x=100, color='red', linestyle='--', linewidth=2, label='Poverty line')\n",
    "axes[1].axvline(x=200, color='green', linestyle='--', linewidth=2, label='Stable threshold')\n",
    "axes[1].set_xlabel('POVPIP (Income-to-Poverty Ratio %)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('POVPIP Distribution (0-250%)')\n",
    "axes[1].legend(fontsize=8)\n",
    "\n",
    "# 3. Create multiclass poverty classification\n",
    "def classify_poverty(povpip_val):\n",
    "    if pd.isna(povpip_val):\n",
    "        return None\n",
    "    elif povpip_val <= 50:\n",
    "        return 'Deep Poverty'\n",
    "    elif povpip_val <= 100:\n",
    "        return 'Poverty'\n",
    "    elif povpip_val <= 200:\n",
    "        return 'Near Poverty'\n",
    "    else:\n",
    "        return 'Stable'\n",
    "\n",
    "df['poverty_class'] = df['POVPIP'].apply(classify_poverty)\n",
    "\n",
    "# Order for display\n",
    "class_order = ['Deep Poverty', 'Poverty', 'Near Poverty', 'Stable']\n",
    "class_counts = df['poverty_class'].value_counts().reindex(class_order)\n",
    "class_colors = ['#8B0000', '#e74c3c', '#f39c12', '#2ecc71']\n",
    "\n",
    "bars = axes[2].bar(class_order, class_counts.values, color=class_colors, edgecolor='black')\n",
    "axes[2].set_ylabel('Count')\n",
    "axes[2].set_xlabel('Poverty Class')\n",
    "axes[2].set_title('Multiclass Poverty Classification')\n",
    "plt.setp(axes[2].xaxis.get_majorticklabels(), rotation=15, ha='right')\n",
    "\n",
    "# Add percentage labels on bars\n",
    "total_valid = df['poverty_class'].notna().sum()\n",
    "for bar, count in zip(bars, class_counts.values):\n",
    "    pct = count / total_valid * 100\n",
    "    axes[2].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 5000, \n",
    "                 f'{pct:.1f}%', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('EDA_data/povpip_distribution_multiclass.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nPoverty Statistics (Multiclass):\")\n",
    "print(f\"Records with POVPIP data: {povpip.shape[0]:,}\")\n",
    "print(f\"Records missing POVPIP: {df['POVPIP'].isna().sum():,}\")\n",
    "print(f\"\\nPoverty Class Breakdown:\")\n",
    "for cls in class_order:\n",
    "    count = class_counts[cls]\n",
    "    pct = count / total_valid * 100\n",
    "    print(f\"  {cls:15}: {count:,} ({pct:.2f}%)\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "jv1v47l5p3",
   "metadata": {},
   "source": [
    "## Correlation Analysis with POVPIP\n",
    "\n",
    "We'll compute correlations between numeric features and the target variable (POVPIP) to identify which features are most predictive of poverty status."
   ]
  },
  {
   "cell_type": "code",
   "id": "w7jz0ipm6yf",
   "metadata": {},
   "source": [
    "# Identify numeric columns for correlation analysis\n",
    "import warnings\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Remove POVPIP and poverty (our target) from feature list\n",
    "feature_cols = [c for c in numeric_cols if c not in ['POVPIP', 'poverty']]\n",
    "\n",
    "print(f\"Total numeric features for correlation: {len(feature_cols)}\")\n",
    "\n",
    "# Calculate correlation with POVPIP (using only non-null POVPIP records)\n",
    "df_valid = df[df['POVPIP'].notna()].copy()\n",
    "\n",
    "correlations = {}\n",
    "for col in feature_cols:\n",
    "    col_data = df_valid[col].dropna()\n",
    "    \n",
    "    # Skip if not enough data or constant values\n",
    "    if len(col_data) < 100:\n",
    "        continue\n",
    "    if col_data.nunique() <= 1:\n",
    "        continue\n",
    "    \n",
    "    # Get matching POVPIP values\n",
    "    valid_idx = col_data.index\n",
    "    povpip_matched = df_valid.loc[valid_idx, 'POVPIP']\n",
    "    \n",
    "    # Standardize to avoid overflow with large values\n",
    "    col_standardized = (col_data - col_data.mean()) / (col_data.std() + 1e-10)\n",
    "    povpip_standardized = (povpip_matched - povpip_matched.mean()) / (povpip_matched.std() + 1e-10)\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        try:\n",
    "            corr, p_val = stats.pearsonr(col_standardized, povpip_standardized)\n",
    "            if not np.isnan(corr) and not np.isinf(corr):\n",
    "                correlations[col] = {'correlation': corr, 'p_value': p_val, 'abs_corr': abs(corr)}\n",
    "        except Exception:\n",
    "            pass  # Skip problematic columns\n",
    "\n",
    "# Convert to DataFrame and sort by absolute correlation\n",
    "corr_df = pd.DataFrame(correlations).T\n",
    "corr_df = corr_df.sort_values('abs_corr', ascending=False)\n",
    "corr_df = corr_df.reset_index().rename(columns={'index': 'column'})\n",
    "\n",
    "# Merge with labels for interpretability\n",
    "corr_df = corr_df.merge(df_dict[['column', 'label']], on='column', how='left')\n",
    "\n",
    "# Create a short label for display\n",
    "corr_df['short_label'] = corr_df['label'].apply(lambda x: str(x)[:45] + '...' if len(str(x)) > 45 else str(x))\n",
    "corr_df['display_name'] = corr_df['column'] + ' - ' + corr_df['short_label']\n",
    "\n",
    "print(f\"\\nTop 35 features correlated with POVPIP (income-to-poverty ratio):\")\n",
    "print(\"-\" * 90)\n",
    "for i, row in corr_df.head(35).iterrows():\n",
    "    print(f\"{row['column']:12} | r={row['correlation']:+.3f} | {row['short_label']}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ktqpgxjn56",
   "metadata": {},
   "source": [
    "# Visualize top correlations with POVPIP (with labels!)\n",
    "top_n = 25\n",
    "top_corr = corr_df.head(top_n).copy()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "colors = ['#e74c3c' if x < 0 else '#2ecc71' for x in top_corr['correlation']]\n",
    "\n",
    "# Use display names (code + short label)\n",
    "y_labels = [f\"{row['column']} - {row['short_label'][:35]}\" for _, row in top_corr.iterrows()]\n",
    "\n",
    "ax.barh(range(len(top_corr)), top_corr['correlation'], color=colors, edgecolor='black')\n",
    "ax.set_yticks(range(len(top_corr)))\n",
    "ax.set_yticklabels(y_labels, fontsize=9)\n",
    "ax.set_xlabel('Pearson Correlation with POVPIP', fontsize=11)\n",
    "ax.set_title(f'Top {top_n} Features Correlated with Income-to-Poverty Ratio', fontsize=12)\n",
    "ax.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Add correlation values on bars\n",
    "for i, (idx, row) in enumerate(top_corr.iterrows()):\n",
    "    ax.text(row['correlation'] + 0.01 if row['correlation'] > 0 else row['correlation'] - 0.01, \n",
    "            i, f\"{row['correlation']:.3f}\", va='center', \n",
    "            ha='left' if row['correlation'] > 0 else 'right', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('EDA_data/correlation_with_povpip.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"- GREEN (positive): Higher values = HIGHER income-to-poverty ratio (less likely to be poor)\")\n",
    "print(\"- RED (negative): Higher values = LOWER income-to-poverty ratio (more likely to be poor)\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "tm1s81g2ute",
   "metadata": {},
   "source": [
    "# Correlation heatmap for top features + POVPIP\n",
    "top_features = corr_df.head(15)['column'].tolist() + ['POVPIP']\n",
    "\n",
    "# Create correlation matrix for these features\n",
    "corr_matrix = df_valid[top_features].corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='RdYlGn', center=0, \n",
    "            fmt='.2f', linewidths=0.5, ax=ax,\n",
    "            annot_kws={'size': 8})\n",
    "ax.set_title('Correlation Heatmap: Top 15 Features + POVPIP')\n",
    "plt.tight_layout()\n",
    "plt.savefig('EDA_data/correlation_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2ppjrgrm22c",
   "metadata": {},
   "source": [
    "## Variance Analysis\n",
    "\n",
    "Features with very low variance don't provide much discriminative power. We'll identify features with:\n",
    "- Near-zero variance (most values are the same)\n",
    "- Highly skewed distributions\n",
    "\n",
    "These features are candidates for removal to reduce dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "id": "dp32u8a6jbl",
   "metadata": {},
   "source": [
    "# Variance analysis for numeric features\n",
    "variance_stats = []\n",
    "\n",
    "for col in feature_cols:\n",
    "    if col in df.columns:\n",
    "        col_data = df[col].dropna()\n",
    "        if len(col_data) > 0:\n",
    "            variance_stats.append({\n",
    "                'column': col,\n",
    "                'variance': col_data.var(),\n",
    "                'std': col_data.std(),\n",
    "                'unique_values': col_data.nunique(),\n",
    "                'mode_pct': col_data.value_counts(normalize=True).iloc[0] * 100 if len(col_data) > 0 else 0,\n",
    "                'non_null_count': len(col_data)\n",
    "            })\n",
    "\n",
    "variance_df = pd.DataFrame(variance_stats)\n",
    "variance_df = variance_df.sort_values('variance', ascending=True)\n",
    "\n",
    "# Low variance features (mode > 95%)\n",
    "low_var_features = variance_df[variance_df['mode_pct'] > 95]\n",
    "print(f\"=== Low Variance Features (mode > 95% of values) ===\")\n",
    "print(f\"Found {len(low_var_features)} features with extremely low variance:\")\n",
    "print(low_var_features[['column', 'mode_pct', 'unique_values']].to_string())\n",
    "\n",
    "# Visualize variance distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram of mode percentages\n",
    "axes[0].hist(variance_df['mode_pct'], bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(x=95, color='red', linestyle='--', label='95% threshold')\n",
    "axes[0].set_xlabel('Mode Percentage (%)')\n",
    "axes[0].set_ylabel('Number of Features')\n",
    "axes[0].set_title('Distribution of Feature Mode Percentages')\n",
    "axes[0].legend()\n",
    "\n",
    "# Number of unique values per feature\n",
    "axes[1].hist(variance_df['unique_values'], bins=30, edgecolor='black', alpha=0.7, color='orange')\n",
    "axes[1].set_xlabel('Number of Unique Values')\n",
    "axes[1].set_ylabel('Number of Features')\n",
    "axes[1].set_title('Distribution of Unique Value Counts')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('EDA_data/variance_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "vr7xmievb58",
   "metadata": {},
   "source": [
    "## Poverty Analysis by Key Demographics\n",
    "\n",
    "Exploring how poverty rates vary across key demographic and socioeconomic factors."
   ]
  },
  {
   "cell_type": "code",
   "id": "5wyljlo1cgi",
   "metadata": {},
   "source": [
    "# Poverty Class Distribution by Age Groups\n",
    "df_analysis = df[df['poverty_class'].notna()].copy()\n",
    "\n",
    "# Create age groups\n",
    "df_analysis['age_group'] = pd.cut(df_analysis['AGEP'], \n",
    "                                   bins=[0, 5, 18, 25, 35, 45, 55, 65, 100],\n",
    "                                   labels=['0-5', '6-18', '19-25', '26-35', '36-45', '46-55', '56-65', '65+'])\n",
    "\n",
    "# Calculate distribution of poverty classes by age group\n",
    "class_order = ['Deep Poverty', 'Poverty', 'Near Poverty', 'Stable']\n",
    "class_colors = {'Deep Poverty': '#8B0000', 'Poverty': '#e74c3c', 'Near Poverty': '#f39c12', 'Stable': '#2ecc71'}\n",
    "\n",
    "poverty_by_age = df_analysis.groupby(['age_group', 'poverty_class']).size().unstack(fill_value=0)\n",
    "poverty_by_age = poverty_by_age[class_order]  # Reorder columns\n",
    "poverty_by_age_pct = poverty_by_age.div(poverty_by_age.sum(axis=1), axis=0) * 100\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Stacked bar chart showing poverty class distribution by age\n",
    "poverty_by_age_pct.plot(kind='bar', stacked=True, ax=axes[0], \n",
    "                        color=[class_colors[c] for c in class_order], edgecolor='black', linewidth=0.5)\n",
    "axes[0].set_xlabel('Age Group')\n",
    "axes[0].set_ylabel('Percentage (%)')\n",
    "axes[0].set_title('Poverty Class Distribution by Age Group')\n",
    "axes[0].legend(title='Poverty Class', bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=0)\n",
    "\n",
    "# Deep Poverty + Poverty rate (vulnerable population) by age\n",
    "vulnerable_rate = (poverty_by_age[['Deep Poverty', 'Poverty']].sum(axis=1) / \n",
    "                   poverty_by_age.sum(axis=1) * 100)\n",
    "bars = axes[1].bar(vulnerable_rate.index.astype(str), vulnerable_rate.values, \n",
    "                   color='#c0392b', edgecolor='black')\n",
    "axes[1].set_xlabel('Age Group')\n",
    "axes[1].set_ylabel('Vulnerable Rate (Deep Poverty + Poverty) %')\n",
    "axes[1].set_title('Below Poverty Line Rate by Age Group')\n",
    "axes[1].axhline(y=vulnerable_rate.mean(), color='blue', linestyle='--', label=f'Average: {vulnerable_rate.mean():.1f}%')\n",
    "axes[1].legend()\n",
    "for bar, rate in zip(bars, vulnerable_rate.values):\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.3, \n",
    "                 f'{rate:.1f}%', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('EDA_data/poverty_class_by_age.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPoverty Class Distribution by Age Group (%):\")\n",
    "print(poverty_by_age_pct.round(1).to_string())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4hdj9r6pm34",
   "metadata": {},
   "source": [
    "# Poverty Class Distribution by Education Level (SCHL - Educational Attainment)\n",
    "# SCHL values: 1-15 = no high school diploma, 16-17 = high school, 18-19 = some college, \n",
    "# 20 = Associate's, 21 = Bachelor's, 22 = Master's, 23 = Professional, 24 = Doctorate\n",
    "\n",
    "edu_mapping = {\n",
    "    'No HS Diploma': list(range(1, 16)),\n",
    "    'High School': [16, 17],\n",
    "    'Some College': [18, 19],\n",
    "    \"Associate's\": [20],\n",
    "    \"Bachelor's\": [21],\n",
    "    \"Master's\": [22],\n",
    "    'Professional/Doctorate': [23, 24]\n",
    "}\n",
    "\n",
    "def map_education(schl):\n",
    "    if pd.isna(schl):\n",
    "        return None\n",
    "    for label, values in edu_mapping.items():\n",
    "        if int(schl) in values:\n",
    "            return label\n",
    "    return None\n",
    "\n",
    "df_analysis['education'] = df_analysis['SCHL'].apply(map_education)\n",
    "\n",
    "# Calculate poverty class distribution by education\n",
    "edu_order = ['No HS Diploma', 'High School', 'Some College', \"Associate's\", \"Bachelor's\", \"Master's\", 'Professional/Doctorate']\n",
    "class_order = ['Deep Poverty', 'Poverty', 'Near Poverty', 'Stable']\n",
    "class_colors = {'Deep Poverty': '#8B0000', 'Poverty': '#e74c3c', 'Near Poverty': '#f39c12', 'Stable': '#2ecc71'}\n",
    "\n",
    "poverty_by_edu = df_analysis.dropna(subset=['education']).groupby(['education', 'poverty_class']).size().unstack(fill_value=0)\n",
    "poverty_by_edu = poverty_by_edu.reindex(edu_order)[class_order]\n",
    "poverty_by_edu_pct = poverty_by_edu.div(poverty_by_edu.sum(axis=1), axis=0) * 100\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Stacked bar chart\n",
    "poverty_by_edu_pct.plot(kind='bar', stacked=True, ax=axes[0],\n",
    "                        color=[class_colors[c] for c in class_order], edgecolor='black', linewidth=0.5)\n",
    "axes[0].set_xlabel('Education Level')\n",
    "axes[0].set_ylabel('Percentage (%)')\n",
    "axes[0].set_title('Poverty Class Distribution by Education Level')\n",
    "axes[0].legend(title='Poverty Class', bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "plt.setp(axes[0].xaxis.get_majorticklabels(), rotation=30, ha='right')\n",
    "\n",
    "# Vulnerable rate (Deep Poverty + Poverty) by education\n",
    "vulnerable_rate = (poverty_by_edu[['Deep Poverty', 'Poverty']].sum(axis=1) / \n",
    "                   poverty_by_edu.sum(axis=1) * 100)\n",
    "colors_gradient = plt.cm.RdYlGn_r(np.linspace(0.2, 0.8, len(vulnerable_rate)))\n",
    "bars = axes[1].bar(range(len(vulnerable_rate)), vulnerable_rate.values, color=colors_gradient, edgecolor='black')\n",
    "axes[1].set_xticks(range(len(vulnerable_rate)))\n",
    "axes[1].set_xticklabels(edu_order, rotation=30, ha='right')\n",
    "axes[1].set_xlabel('Education Level')\n",
    "axes[1].set_ylabel('Below Poverty Line Rate (%)')\n",
    "axes[1].set_title('Poverty Rate by Educational Attainment')\n",
    "for bar, rate in zip(bars, vulnerable_rate.values):\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.3, \n",
    "                 f'{rate:.1f}%', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('EDA_data/poverty_class_by_education.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPoverty Class Distribution by Education Level (%):\")\n",
    "print(poverty_by_edu_pct.round(1).to_string())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "qz1xtr4l7",
   "metadata": {},
   "source": [
    "# Poverty Class Distribution by Employment Status (ESR - Employment Status Recode)\n",
    "esr_mapping = {\n",
    "    1: 'Employed - At Work',\n",
    "    2: 'Employed - With Job',\n",
    "    3: 'Unemployed',\n",
    "    4: 'Armed Forces - At Work',\n",
    "    5: 'Armed Forces - With Job',\n",
    "    6: 'Not in Labor Force'\n",
    "}\n",
    "\n",
    "df_analysis['employment'] = df_analysis['ESR'].map(esr_mapping)\n",
    "\n",
    "# Calculate poverty class distribution by employment\n",
    "class_order = ['Deep Poverty', 'Poverty', 'Near Poverty', 'Stable']\n",
    "class_colors = {'Deep Poverty': '#8B0000', 'Poverty': '#e74c3c', 'Near Poverty': '#f39c12', 'Stable': '#2ecc71'}\n",
    "\n",
    "poverty_by_emp = df_analysis.dropna(subset=['employment']).groupby(['employment', 'poverty_class']).size().unstack(fill_value=0)\n",
    "poverty_by_emp = poverty_by_emp[class_order]\n",
    "poverty_by_emp_pct = poverty_by_emp.div(poverty_by_emp.sum(axis=1), axis=0) * 100\n",
    "\n",
    "# Sort by vulnerable rate (deep poverty + poverty)\n",
    "vulnerable_rate = (poverty_by_emp[['Deep Poverty', 'Poverty']].sum(axis=1) / \n",
    "                   poverty_by_emp.sum(axis=1) * 100)\n",
    "emp_order = vulnerable_rate.sort_values(ascending=False).index\n",
    "poverty_by_emp_pct = poverty_by_emp_pct.reindex(emp_order)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Stacked horizontal bar chart\n",
    "poverty_by_emp_pct.plot(kind='barh', stacked=True, ax=axes[0],\n",
    "                        color=[class_colors[c] for c in class_order], edgecolor='black', linewidth=0.5)\n",
    "axes[0].set_xlabel('Percentage (%)')\n",
    "axes[0].set_ylabel('Employment Status')\n",
    "axes[0].set_title('Poverty Class Distribution by Employment Status')\n",
    "axes[0].legend(title='Poverty Class', bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "\n",
    "# Vulnerable rate comparison\n",
    "vulnerable_sorted = vulnerable_rate.reindex(emp_order)\n",
    "colors_gradient = plt.cm.RdYlGn_r(np.linspace(0.2, 0.8, len(vulnerable_sorted)))\n",
    "bars = axes[1].barh(range(len(vulnerable_sorted)), vulnerable_sorted.values, color=colors_gradient, edgecolor='black')\n",
    "axes[1].set_yticks(range(len(vulnerable_sorted)))\n",
    "axes[1].set_yticklabels(emp_order)\n",
    "axes[1].set_xlabel('Below Poverty Line Rate (%)')\n",
    "axes[1].set_title('Poverty Rate by Employment Status')\n",
    "for bar, rate in zip(bars, vulnerable_sorted.values):\n",
    "    axes[1].text(bar.get_width() + 0.5, bar.get_y() + bar.get_height()/2, \n",
    "                 f'{rate:.1f}%', ha='left', va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('EDA_data/poverty_class_by_employment.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPoverty Class Distribution by Employment Status (%):\")\n",
    "print(poverty_by_emp_pct.round(1).to_string())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1c3f1450-ffce-4106-8776-f16285234cbc",
   "metadata": {},
   "source": [
    "#FYI\n",
    "#In US Census and labor force statistics (such as the Current Population Survey), both \"at work\" and \"with a job but not at work\" are subsets of the employed population. The key difference lies in whether the person physically performed any work during the specific \"reference week\" (the week before the survey). \n",
    "#At Work: Individuals who worked at least one hour for pay or profit during the reference week, including those in their own business, profession, or farm.\n",
    "#With a Job but Not at Work: Individuals who have a job or business but did not work at all during the reference week due to temporary absences, such as vacation, illness, bad weather, childcare problems, or labor-management disputes. "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a0rrnave5gq",
   "metadata": {},
   "source": [
    "# Poverty Class Distribution by Health Insurance Status\n",
    "# HICOV: 1 = With health insurance, 2 = Without health insurance\n",
    "hicov_mapping = {1: 'With Insurance', 2: 'Without Insurance'}\n",
    "df_analysis['health_insurance'] = df_analysis['HICOV'].map(hicov_mapping)\n",
    "\n",
    "# Also look at public vs private coverage\n",
    "df_analysis['public_coverage'] = df_analysis['PUBCOV'].map({1: 'Has Public Coverage', 2: 'No Public Coverage'})\n",
    "df_analysis['private_coverage'] = df_analysis['PRIVCOV'].map({1: 'Has Private Coverage', 2: 'No Private Coverage'})\n",
    "\n",
    "class_order = ['Deep Poverty', 'Poverty', 'Near Poverty', 'Stable']\n",
    "class_colors = {'Deep Poverty': '#8B0000', 'Poverty': '#e74c3c', 'Near Poverty': '#f39c12', 'Stable': '#2ecc71'}\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# 1. Health insurance coverage - stacked bar\n",
    "ins_dist = df_analysis.dropna(subset=['health_insurance']).groupby(['health_insurance', 'poverty_class']).size().unstack(fill_value=0)\n",
    "ins_dist = ins_dist[class_order]\n",
    "ins_dist_pct = ins_dist.div(ins_dist.sum(axis=1), axis=0) * 100\n",
    "ins_dist_pct.plot(kind='bar', stacked=True, ax=axes[0],\n",
    "                  color=[class_colors[c] for c in class_order], edgecolor='black', linewidth=0.5)\n",
    "axes[0].set_xlabel('')\n",
    "axes[0].set_ylabel('Percentage (%)')\n",
    "axes[0].set_title('Poverty Class by Health Insurance Status')\n",
    "axes[0].legend(title='Class', fontsize=8)\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=0)\n",
    "\n",
    "# 2. Public coverage - stacked bar\n",
    "pub_dist = df_analysis.dropna(subset=['public_coverage']).groupby(['public_coverage', 'poverty_class']).size().unstack(fill_value=0)\n",
    "pub_dist = pub_dist[class_order]\n",
    "pub_dist_pct = pub_dist.div(pub_dist.sum(axis=1), axis=0) * 100\n",
    "pub_dist_pct.plot(kind='bar', stacked=True, ax=axes[1],\n",
    "                  color=[class_colors[c] for c in class_order], edgecolor='black', linewidth=0.5)\n",
    "axes[1].set_xlabel('')\n",
    "axes[1].set_ylabel('Percentage (%)')\n",
    "axes[1].set_title('Poverty Class by Public Health Coverage')\n",
    "axes[1].legend(title='Class', fontsize=8)\n",
    "axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=0)\n",
    "\n",
    "# 3. Private coverage - stacked bar\n",
    "priv_dist = df_analysis.dropna(subset=['private_coverage']).groupby(['private_coverage', 'poverty_class']).size().unstack(fill_value=0)\n",
    "priv_dist = priv_dist[class_order]\n",
    "priv_dist_pct = priv_dist.div(priv_dist.sum(axis=1), axis=0) * 100\n",
    "priv_dist_pct.plot(kind='bar', stacked=True, ax=axes[2],\n",
    "                   color=[class_colors[c] for c in class_order], edgecolor='black', linewidth=0.5)\n",
    "axes[2].set_xlabel('')\n",
    "axes[2].set_ylabel('Percentage (%)')\n",
    "axes[2].set_title('Poverty Class by Private Health Coverage')\n",
    "axes[2].legend(title='Class', fontsize=8)\n",
    "axes[2].set_xticklabels(axes[2].get_xticklabels(), rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('EDA_data/poverty_class_by_health_insurance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPoverty Class by Insurance Type (% distribution):\")\n",
    "print(\"\\nHealth Insurance Status:\")\n",
    "print(ins_dist_pct.round(1).to_string())\n",
    "print(\"\\nPublic Coverage:\")\n",
    "print(pub_dist_pct.round(1).to_string())\n",
    "print(\"\\nPrivate Coverage:\")\n",
    "print(priv_dist_pct.round(1).to_string())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "tj90r4kzpih",
   "metadata": {},
   "source": [
    "# Poverty Class Distribution by Disability Status\n",
    "dis_mapping = {1: 'Has Disability', 2: 'No Disability'}\n",
    "df_analysis['disability'] = df_analysis['DIS'].map(dis_mapping)\n",
    "\n",
    "class_order = ['Deep Poverty', 'Poverty', 'Near Poverty', 'Stable']\n",
    "class_colors = {'Deep Poverty': '#8B0000', 'Poverty': '#e74c3c', 'Near Poverty': '#f39c12', 'Stable': '#2ecc71'}\n",
    "\n",
    "# Calculate poverty class distribution by disability\n",
    "dis_dist = df_analysis.dropna(subset=['disability']).groupby(['disability', 'poverty_class']).size().unstack(fill_value=0)\n",
    "dis_dist = dis_dist[class_order]\n",
    "dis_dist_pct = dis_dist.div(dis_dist.sum(axis=1), axis=0) * 100\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Stacked bar by disability status\n",
    "dis_dist_pct.plot(kind='bar', stacked=True, ax=axes[0],\n",
    "                  color=[class_colors[c] for c in class_order], edgecolor='black', linewidth=0.5)\n",
    "axes[0].set_xlabel('Disability Status')\n",
    "axes[0].set_ylabel('Percentage (%)')\n",
    "axes[0].set_title('Poverty Class Distribution by Disability Status')\n",
    "axes[0].legend(title='Poverty Class')\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=0)\n",
    "\n",
    "# Individual disability types - vulnerable rate comparison\n",
    "disability_cols = ['DDRS', 'DEAR', 'DEYE', 'DOUT', 'DPHY', 'DREM']\n",
    "disability_labels = ['Self-care', 'Hearing', 'Vision', 'Independent Living', 'Ambulatory', 'Cognitive']\n",
    "\n",
    "disability_vuln_rates = []\n",
    "for col, label in zip(disability_cols, disability_labels):\n",
    "    has_dis_data = df_analysis[df_analysis[col] == 1]\n",
    "    no_dis_data = df_analysis[df_analysis[col] == 2]\n",
    "    \n",
    "    has_dis_vuln = has_dis_data['poverty_class'].isin(['Deep Poverty', 'Poverty']).mean() * 100\n",
    "    no_dis_vuln = no_dis_data['poverty_class'].isin(['Deep Poverty', 'Poverty']).mean() * 100\n",
    "    \n",
    "    disability_vuln_rates.append({\n",
    "        'Disability Type': label, \n",
    "        'Has Disability': has_dis_vuln, \n",
    "        'No Disability': no_dis_vuln\n",
    "    })\n",
    "\n",
    "dis_df = pd.DataFrame(disability_vuln_rates)\n",
    "\n",
    "x = np.arange(len(dis_df))\n",
    "width = 0.35\n",
    "bars1 = axes[1].bar(x - width/2, dis_df['Has Disability'], width, label='Has Disability', color='#c0392b', edgecolor='black')\n",
    "bars2 = axes[1].bar(x + width/2, dis_df['No Disability'], width, label='No Disability', color='#27ae60', edgecolor='black')\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(dis_df['Disability Type'], rotation=30, ha='right')\n",
    "axes[1].set_ylabel('Below Poverty Line Rate (%)')\n",
    "axes[1].set_title('Poverty Rate by Specific Disability Type')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('EDA_data/poverty_class_by_disability.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPoverty Class Distribution by Disability Status (%):\")\n",
    "print(dis_dist_pct.round(1).to_string())\n",
    "print(\"\\n\\nBelow Poverty Line Rate by Disability Type:\")\n",
    "print(dis_df.to_string(index=False))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1wf2u4hvnfo",
   "metadata": {},
   "source": [
    "# Poverty Class Trends Over Time (by Year)\n",
    "class_order = ['Deep Poverty', 'Poverty', 'Near Poverty', 'Stable']\n",
    "class_colors = {'Deep Poverty': '#8B0000', 'Poverty': '#e74c3c', 'Near Poverty': '#f39c12', 'Stable': '#2ecc71'}\n",
    "\n",
    "# Calculate poverty class distribution by year\n",
    "poverty_by_year = df_analysis.groupby(['year', 'poverty_class']).size().unstack(fill_value=0)\n",
    "poverty_by_year = poverty_by_year[class_order]\n",
    "poverty_by_year_pct = poverty_by_year.div(poverty_by_year.sum(axis=1), axis=0) * 100\n",
    "\n",
    "# Vulnerable rate (Deep Poverty + Poverty) by year\n",
    "vulnerable_by_year = (poverty_by_year[['Deep Poverty', 'Poverty']].sum(axis=1) / \n",
    "                      poverty_by_year.sum(axis=1) * 100)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Line chart of each poverty class over time\n",
    "for cls in class_order:\n",
    "    axes[0].plot(poverty_by_year_pct.index, poverty_by_year_pct[cls], \n",
    "                 marker='o', linewidth=2, markersize=6, color=class_colors[cls], label=cls)\n",
    "axes[0].set_xlabel('Year')\n",
    "axes[0].set_ylabel('Percentage (%)')\n",
    "axes[0].set_title('Poverty Class Distribution Over Time')\n",
    "axes[0].legend(title='Poverty Class')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Vulnerable rate trend\n",
    "axes[1].plot(vulnerable_by_year.index, vulnerable_by_year.values, \n",
    "             marker='o', linewidth=2, markersize=8, color='#c0392b')\n",
    "axes[1].fill_between(vulnerable_by_year.index, vulnerable_by_year.values, alpha=0.3, color='#c0392b')\n",
    "axes[1].set_xlabel('Year')\n",
    "axes[1].set_ylabel('Below Poverty Line Rate (%)')\n",
    "axes[1].set_title('Poverty Rate Trend in California (ACS 1-Year Estimates)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "for yr, rate in zip(vulnerable_by_year.index, vulnerable_by_year.values):\n",
    "    axes[1].annotate(f'{rate:.1f}%', (yr, rate), textcoords=\"offset points\", \n",
    "                     xytext=(0, 8), ha='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('EDA_data/poverty_class_by_year.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPoverty Class Distribution by Year (%):\")\n",
    "print(poverty_by_year_pct.round(1).to_string())\n",
    "print(f\"\\nBelow Poverty Line Rate by Year:\")\n",
    "for yr, rate in vulnerable_by_year.items():\n",
    "    print(f\"  {yr}: {rate:.2f}%\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "jwqczvcseo9",
   "metadata": {},
   "source": [
    "## Feature Reduction Recommendations\n",
    "\n",
    "Based on our analysis, we'll identify features to keep and features to drop based on:\n",
    "1. **Avoid Data Leakage** - Remove ALL income variables (PINCP, PERNP, WAGP, RETP, etc.) since we're predicting poverty from non-income risk factors\n",
    "2. **Correlation with POVPIP** - Keep features with |correlation| >= 0.08\n",
    "3. **Variance** - Drop features with very low variance (mode >95%)\n",
    "4. **Use Summary Recodes Only** - Keep DIS (not individual disabilities), HICOV (not HINS1-7), ESR (not NWLK/NWLA) to avoid multicollinearity\n",
    "5. **Simplify Race Variables** - Keep only RAC1P + HISP, drop redundant binary race flags"
   ]
  },
  {
   "cell_type": "code",
   "id": "h52j6nv50bv",
   "metadata": {},
   "source": [
    "# Feature Selection Strategy\n",
    "\n",
    "# 1. INCOME FEATURES TO EXCLUDE (Data Leakage)\n",
    "# All income variables are used to calculate POVPIP - including them defeats the purpose\n",
    "income_features = ['PINCP', 'PERNP', 'WAGP', 'SEMP', 'INTP', 'RETP', 'SSP', 'SSIP', 'PAP', 'OIP']\n",
    "print(\"=== Features to EXCLUDE (Income - Data Leakage) ===\")\n",
    "print(\"These are directly related to income, which determines POVPIP:\")\n",
    "for f in income_features:\n",
    "    if f in corr_df['column'].values:\n",
    "        row = corr_df[corr_df['column'] == f].iloc[0]\n",
    "        print(f\"  {f:8} | r={row['correlation']:+.3f} | {row['short_label']}\")\n",
    "\n",
    "# 2. DETAILED FEATURES TO EXCLUDE (Use Summary Recodes Instead)\n",
    "# These create multicollinearity - the summary recodes capture the same info\n",
    "detailed_to_exclude = [\n",
    "    # Individual disabilities (use DIS instead)\n",
    "    'DDRS', 'DEAR', 'DEYE', 'DOUT', 'DPHY', 'DREM',\n",
    "    # Individual insurance types (use HICOV, PRIVCOV, PUBCOV instead)\n",
    "    'HINS1', 'HINS2', 'HINS3', 'HINS4', 'HINS5', 'HINS6', 'HINS7',\n",
    "    # Raw employment variables (use ESR instead)\n",
    "    'NWLK', 'NWLA', 'NWAB', 'NWAV', 'NWRE',\n",
    "    # Redundant race variables (use RAC1P + HISP instead)\n",
    "    'RACWHT', 'RACASN', 'RACSOR', 'RACBLK', 'RACNH', 'RACPI', 'RACAIAN', 'RAC2P', 'RAC3P', 'ANC', 'ANC1P', 'ANC2P', 'RACNUM'\n",
    "]\n",
    "print(f\"\\n=== Features to EXCLUDE (Redundant/Detailed - Use Summaries) ===\")\n",
    "print(\"Using summary recodes instead to avoid multicollinearity:\")\n",
    "print(f\"  Disability: Use DIS, not {[x for x in detailed_to_exclude if x.startswith('D') and x != 'DIS']}\")\n",
    "print(f\"  Insurance: Use HICOV/PRIVCOV/PUBCOV, not HINS1-7\")\n",
    "print(f\"  Employment: Use ESR, not NWLK/NWLA/etc.\")\n",
    "print(f\"  Race: Use RAC1P + HISP, not binary race flags\")\n",
    "\n",
    "# 3. Identify features with meaningful correlation (|r| >= 0.08)\n",
    "min_corr = 0.08\n",
    "all_exclusions = set(income_features + detailed_to_exclude)\n",
    "high_corr_features = corr_df[corr_df['abs_corr'] >= min_corr]['column'].tolist()\n",
    "high_corr_features = [f for f in high_corr_features if f not in all_exclusions]\n",
    "\n",
    "print(f\"\\n=== Features with |correlation| >= {min_corr} (after exclusions): {len(high_corr_features)} ===\")\n",
    "for f in high_corr_features:\n",
    "    row = corr_df[corr_df['column'] == f].iloc[0]\n",
    "    print(f\"  {f:12} | r={row['correlation']:+.3f} | {row['short_label']}\")\n",
    "\n",
    "# 4. Identify low variance features to drop (mode > 95%)\n",
    "low_var_to_drop = variance_df[variance_df['mode_pct'] > 95]['column'].tolist()\n",
    "print(f\"\\n=== Low Variance Features to DROP (mode > 95%): {len(low_var_to_drop)} ===\")\n",
    "if low_var_to_drop:\n",
    "    print(low_var_to_drop)\n",
    "else:\n",
    "    print(\"  None\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "39p3u56y8un",
   "metadata": {},
   "source": [
    "# 5. Compile final recommended feature set\n",
    "\n",
    "# Start with features that have meaningful correlation with POVPIP (already filtered)\n",
    "recommended_features = set(high_corr_features)\n",
    "\n",
    "# Remove low variance features\n",
    "recommended_features = recommended_features - set(low_var_to_drop)\n",
    "\n",
    "# Add domain-important features that might have lower correlation but are theoretically important\n",
    "domain_important = ['AGEP', 'SEX', 'RAC1P', 'HISP', 'CIT', 'NATIVITY', 'MIG']\n",
    "for f in domain_important:\n",
    "    if f in feature_cols and f not in all_exclusions:\n",
    "        recommended_features.add(f)\n",
    "\n",
    "recommended_features = sorted(list(recommended_features))\n",
    "\n",
    "# Group features by category for review\n",
    "categories = {\n",
    "    'Demographics': ['AGEP', 'SEX', 'MAR', 'MSP', 'CIT', 'NATIVITY', 'MIG', 'QTRBIR'],\n",
    "    'Race/Ethnicity': ['RAC1P', 'HISP'],\n",
    "    'Education': ['SCHL', 'SCH'],\n",
    "    'Employment': ['ESR', 'COW', 'WRK', 'WKL', 'WKHP', 'OCCP', 'INDP', 'SOCP', 'NAICSP'],\n",
    "    'Health Insurance': ['HICOV', 'PRIVCOV', 'PUBCOV'],\n",
    "    'Disability': ['DIS'],\n",
    "    'Geography': ['DIVISION', 'REGION', 'PUMA', 'POBP', 'POWSP', 'POWPUMA'],\n",
    "    'Household': ['RC', 'OC', 'GCL', 'PAOC']\n",
    "}\n",
    "\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"FINAL RECOMMENDED FEATURE SET: {len(recommended_features)} features\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "for category, cols in categories.items():\n",
    "    cat_features = [f for f in recommended_features if f in cols]\n",
    "    if cat_features:\n",
    "        print(f\"\\n{category} ({len(cat_features)}):\")\n",
    "        for f in cat_features:\n",
    "            if f in corr_df['column'].values:\n",
    "                row = corr_df[corr_df['column'] == f].iloc[0]\n",
    "                print(f\"  {f:12} | r={row['correlation']:+.3f} | {row['short_label']}\")\n",
    "            else:\n",
    "                label_vals = df_dict[df_dict['column'] == f]['label'].values\n",
    "                label = str(label_vals[0])[:45] if len(label_vals) > 0 else 'N/A'\n",
    "                print(f\"  {f:12} | (domain)    | {label}\")\n",
    "\n",
    "# Check for any uncategorized\n",
    "all_categorized = [f for cols in categories.values() for f in cols]\n",
    "uncategorized = [f for f in recommended_features if f not in all_categorized]\n",
    "if uncategorized:\n",
    "    print(f\"\\nOther ({len(uncategorized)}):\")\n",
    "    for f in uncategorized:\n",
    "        if f in corr_df['column'].values:\n",
    "            row = corr_df[corr_df['column'] == f].iloc[0]\n",
    "            print(f\"  {f:12} | r={row['correlation']:+.3f} | {row['short_label']}\")\n",
    "\n",
    "# 6. Verify no highly correlated pairs remain in our final set\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"MULTICOLLINEARITY CHECK\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "numeric_recommended = [f for f in recommended_features if f in df_valid.columns]\n",
    "corr_matrix_final = df_valid[numeric_recommended].corr()\n",
    "\n",
    "high_corr_pairs = []\n",
    "for i in range(len(corr_matrix_final.columns)):\n",
    "    for j in range(i+1, len(corr_matrix_final.columns)):\n",
    "        corr_val = corr_matrix_final.iloc[i, j]\n",
    "        if abs(corr_val) > 0.80:\n",
    "            high_corr_pairs.append({\n",
    "                'feature1': corr_matrix_final.columns[i],\n",
    "                'feature2': corr_matrix_final.columns[j],\n",
    "                'correlation': corr_val\n",
    "            })\n",
    "\n",
    "if high_corr_pairs:\n",
    "    print(f\"\\nWarning: {len(high_corr_pairs)} highly correlated pairs (|r| > 0.80):\")\n",
    "    for pair in high_corr_pairs:\n",
    "        print(f\"  {pair['feature1']} <-> {pair['feature2']}: r={pair['correlation']:.3f}\")\n",
    "else:\n",
    "    print(\"\\nNo highly correlated pairs (|r| > 0.80) - feature set is clean!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "07upueoytwxd",
   "metadata": {},
   "source": [
    "# Save recommended features with their descriptions and correlations\n",
    "recommended_dict = df_dict[df_dict['column'].isin(recommended_features)][['column', 'label']].copy()\n",
    "\n",
    "# Add correlation info\n",
    "recommended_dict = recommended_dict.merge(\n",
    "    corr_df[['column', 'correlation', 'abs_corr']], \n",
    "    on='column', \n",
    "    how='left'\n",
    ")\n",
    "recommended_dict = recommended_dict.sort_values('abs_corr', ascending=False)\n",
    "recommended_dict.to_csv('EDA_data/recommended_features.csv', index=False)\n",
    "\n",
    "print(\"=== Final Feature List Saved ===\")\n",
    "print(f\"Total features: {len(recommended_features)}\")\n",
    "print(f\"Saved to: EDA_data/recommended_features.csv\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n=== EXCLUDED FEATURES SUMMARY ===\")\n",
    "print(f\"Income variables (leakage): {len(income_features)}\")\n",
    "print(f\"Detailed/redundant variables: {len(detailed_to_exclude)}\")\n",
    "print(f\"Low variance: {len(low_var_to_drop)}\")\n",
    "\n",
    "print(\"\\n=== FINAL FEATURE COUNT BY CATEGORY ===\")\n",
    "for category, cols in categories.items():\n",
    "    count = len([f for f in recommended_features if f in cols])\n",
    "    if count > 0:\n",
    "        print(f\"  {category}: {count}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b67jbk36l6q",
   "metadata": {},
   "source": [
    "## EDA Summary and Key Findings\n",
    "\n",
    "### Target Variable (POVPIP) - Multiclass Classification\n",
    "We use a 4-class classification based on income-to-poverty ratio (POVPIP):\n",
    "\n",
    "| Class | POVPIP Range | Description |\n",
    "|-------|--------------|-------------|\n",
    "| **Deep Poverty** | 0-50 | Severe economic hardship, less than half the poverty threshold |\n",
    "| **Poverty** | 51-100 | Below poverty line |\n",
    "| **Near Poverty** | 101-200 | Above poverty line but vulnerable, limited financial buffer |\n",
    "| **Stable** | 201+ | More than twice the poverty threshold, relatively secure |\n",
    "\n",
    "### Class Distribution\n",
    "- Significant class imbalance exists - \"Stable\" is the majority class\n",
    "- Deep Poverty and Poverty combined represent approximately 11% of the population\n",
    "- Near Poverty represents an important \"at risk\" population that may benefit from early intervention\n",
    "\n",
    "### Feature Selection Philosophy\n",
    "We focused on identifying **risk factors** that predict poverty susceptibility, NOT income proxies:\n",
    "\n",
    "1. **Excluded ALL income variables** (PINCP, PERNP, WAGP, RETP, SSP, SSIP, PAP, etc.)\n",
    "   - POVPIP is calculated from income, so including income = data leakage\n",
    "   - Goal is to identify at-risk individuals using non-income factors\n",
    "\n",
    "2. **Used Summary Recodes Only** (avoid multicollinearity)\n",
    "   - DIS instead of DDRS, DEAR, DEYE, DOUT, DPHY, DREM\n",
    "   - HICOV/PRIVCOV/PUBCOV instead of HINS1-7\n",
    "   - ESR instead of NWLK, NWLA, NWAB\n",
    "\n",
    "3. **Simplified Race Variables**\n",
    "   - Keep RAC1P (detailed race code) + HISP (Hispanic origin)\n",
    "   - Drop redundant binary flags (RACWHT, RACASN, RACSOR, etc.)\n",
    "\n",
    "### Final Feature Categories\n",
    "- **Health Insurance**: HICOV, PRIVCOV, PUBCOV - strongest predictors\n",
    "- **Employment**: ESR, WRK, WKL, WKHP, OCCP\n",
    "- **Education**: SCHL - educational attainment\n",
    "- **Demographics**: AGEP, SEX, MAR, MSP, CIT, NATIVITY\n",
    "- **Race/Ethnicity**: RAC1P, HISP\n",
    "- **Disability**: DIS\n",
    "\n",
    "### Multiclass Modeling Considerations\n",
    "For model training, consider:\n",
    "- **Class weights** (sklearn: `class_weight='balanced'`) to handle imbalance\n",
    "- **Ordinal regression** since classes have natural ordering (Deep Poverty < Poverty < Near Poverty < Stable)\n",
    "- **Metrics**: Use macro F1-score or weighted F1-score to account for class imbalance\n",
    "- **Focus on recall** for poverty classes to minimize false negatives (missing at-risk individuals)\n",
    "- Consider combining Deep Poverty + Poverty vs Near Poverty vs Stable for a 3-class simplified version if needed"
   ]
  },
  {
   "cell_type": "code",
   "id": "20abcd83-2fc2-4b26-839e-c6faa2a0eda6",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f6a81688-8143-4f1c-a664-7bcd2831224e",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "72c5513d-f3cc-4734-b53b-3edec40cf854",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "159c13a9-c2ae-4699-bf58-57fa355fbb1e",
   "metadata": {},
   "source": [
    "# More Visuals"
   ]
  },
  {
   "cell_type": "code",
   "id": "f9f9da42-d3ec-4172-a93b-a9b3d47d0e30",
   "metadata": {},
   "source": [
    "# Poverty Class Distribution by Sex\n",
    "sex_mapping = {1: 'Male', 2: 'Female'}\n",
    "df_analysis['sex'] = df_analysis['SEX'].map(sex_mapping)\n",
    "\n",
    "class_order = ['Deep Poverty', 'Poverty', 'Near Poverty', 'Stable']\n",
    "class_colors = {'Deep Poverty': '#8B0000', 'Poverty': '#e74c3c', 'Near Poverty': '#f39c12', 'Stable': '#2ecc71'}\n",
    "\n",
    "sex_dist = df_analysis.dropna(subset=['sex']).groupby(['sex', 'poverty_class']).size().unstack(fill_value=0)\n",
    "sex_dist = sex_dist[class_order]\n",
    "sex_dist_pct = sex_dist.div(sex_dist.sum(axis=1), axis=0) * 100\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Stacked bar chart\n",
    "sex_dist_pct.plot(kind='bar', stacked=True, ax=axes[0],\n",
    "                  color=[class_colors[c] for c in class_order], edgecolor='black', linewidth=0.5)\n",
    "axes[0].set_xlabel('Sex')\n",
    "axes[0].set_ylabel('Percentage (%)')\n",
    "axes[0].set_title('Poverty Class Distribution by Sex')\n",
    "axes[0].legend(title='Poverty Class', bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=0)\n",
    "\n",
    "# Pie charts for each sex\n",
    "for i, sex in enumerate(['Male', 'Female']):\n",
    "    ax_pie = axes[1].inset_axes([i*0.5, 0, 0.5, 1])\n",
    "    data = sex_dist.loc[sex]\n",
    "    colors = [class_colors[c] for c in class_order]\n",
    "    wedges, texts, autotexts = ax_pie.pie(data, labels=None, autopct='%1.1f%%', \n",
    "                                           colors=colors, startangle=90, pctdistance=0.75)\n",
    "    ax_pie.set_title(sex, fontsize=12, fontweight='bold')\n",
    "    for autotext in autotexts:\n",
    "        autotext.set_fontsize(8)\n",
    "axes[1].axis('off')\n",
    "axes[1].set_title('Poverty Class Breakdown by Sex', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('EDA_data/poverty_class_by_sex.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPoverty Class Distribution by Sex (%):\")\n",
    "print(sex_dist_pct.round(1).to_string())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "kg6ukwqc3p",
   "metadata": {},
   "source": [
    "# Poverty Class Distribution by Race/Ethnicity (RAC1P)\n",
    "race_mapping = {\n",
    "    1: 'White alone',\n",
    "    2: 'Black/African American',\n",
    "    3: 'American Indian',\n",
    "    4: 'Alaska Native',\n",
    "    5: 'American Indian/Alaska Native',\n",
    "    6: 'Asian alone',\n",
    "    7: 'Native Hawaiian/Pacific Islander',\n",
    "    8: 'Some Other Race',\n",
    "    9: 'Two or More Races'\n",
    "}\n",
    "\n",
    "df_analysis['race'] = df_analysis['RAC1P'].map(race_mapping)\n",
    "\n",
    "# Also create Hispanic/Latino indicator\n",
    "df_analysis['hispanic'] = df_analysis['HISP'].apply(lambda x: 'Hispanic/Latino' if x > 1 else 'Not Hispanic/Latino')\n",
    "\n",
    "class_order = ['Deep Poverty', 'Poverty', 'Near Poverty', 'Stable']\n",
    "class_colors = {'Deep Poverty': '#8B0000', 'Poverty': '#e74c3c', 'Near Poverty': '#f39c12', 'Stable': '#2ecc71'}\n",
    "\n",
    "# Race distribution\n",
    "race_dist = df_analysis.dropna(subset=['race']).groupby(['race', 'poverty_class']).size().unstack(fill_value=0)\n",
    "race_dist = race_dist[class_order]\n",
    "race_dist_pct = race_dist.div(race_dist.sum(axis=1), axis=0) * 100\n",
    "\n",
    "# Sort by poverty rate\n",
    "vulnerable_rate = (race_dist_pct['Deep Poverty'] + race_dist_pct['Poverty'])\n",
    "race_dist_pct = race_dist_pct.loc[vulnerable_rate.sort_values(ascending=False).index]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "race_dist_pct.plot(kind='barh', stacked=True, ax=ax,\n",
    "                   color=[class_colors[c] for c in class_order], edgecolor='black', linewidth=0.5)\n",
    "ax.set_xlabel('Percentage (%)')\n",
    "ax.set_ylabel('Race/Ethnicity')\n",
    "ax.set_title('Poverty Class Distribution by Race (RAC1P)')\n",
    "ax.legend(title='Poverty Class', bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "\n",
    "# Add vulnerable rate labels\n",
    "for i, (idx, row) in enumerate(race_dist_pct.iterrows()):\n",
    "    vuln = row['Deep Poverty'] + row['Poverty']\n",
    "    ax.text(102, i, f'{vuln:.1f}%', va='center', fontsize=9, fontweight='bold', color='#c0392b')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('EDA_data/poverty_class_by_race.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPoverty Rate by Race (Deep Poverty + Poverty %):\")\n",
    "print(vulnerable_rate.sort_values(ascending=False).round(1).to_string())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2bi827lh0kg",
   "metadata": {},
   "source": [
    "# Poverty Class Distribution by Hispanic Origin\n",
    "hisp_dist = df_analysis.dropna(subset=['hispanic']).groupby(['hispanic', 'poverty_class']).size().unstack(fill_value=0)\n",
    "hisp_dist = hisp_dist[class_order]\n",
    "hisp_dist_pct = hisp_dist.div(hisp_dist.sum(axis=1), axis=0) * 100\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Stacked bar chart\n",
    "hisp_dist_pct.plot(kind='bar', stacked=True, ax=axes[0],\n",
    "                   color=[class_colors[c] for c in class_order], edgecolor='black', linewidth=0.5)\n",
    "axes[0].set_xlabel('Hispanic Origin')\n",
    "axes[0].set_ylabel('Percentage (%)')\n",
    "axes[0].set_title('Poverty Class Distribution by Hispanic Origin')\n",
    "axes[0].legend(title='Poverty Class')\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=0)\n",
    "\n",
    "# Donut chart comparison\n",
    "vulnerable_hisp = hisp_dist_pct.loc['Hispanic/Latino', ['Deep Poverty', 'Poverty']].sum()\n",
    "vulnerable_non = hisp_dist_pct.loc['Not Hispanic/Latino', ['Deep Poverty', 'Poverty']].sum()\n",
    "\n",
    "labels = ['Hispanic/Latino', 'Not Hispanic/Latino']\n",
    "vuln_rates = [vulnerable_hisp, vulnerable_non]\n",
    "colors_bar = ['#e74c3c', '#3498db']\n",
    "\n",
    "bars = axes[1].bar(labels, vuln_rates, color=colors_bar, edgecolor='black')\n",
    "axes[1].set_ylabel('Below Poverty Line Rate (%)')\n",
    "axes[1].set_title('Poverty Rate: Hispanic vs Non-Hispanic')\n",
    "axes[1].set_ylim(0, max(vuln_rates) * 1.2)\n",
    "\n",
    "for bar, rate in zip(bars, vuln_rates):\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
    "                 f'{rate:.1f}%', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('EDA_data/poverty_class_by_hispanic.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nPoverty Rate Comparison:\")\n",
    "print(f\"  Hispanic/Latino: {vulnerable_hisp:.1f}%\")\n",
    "print(f\"  Not Hispanic/Latino: {vulnerable_non:.1f}%\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "jf9opvmtwc",
   "metadata": {},
   "source": [
    "# Poverty Class Distribution by Marital Status (MAR)\n",
    "mar_mapping = {\n",
    "    1: 'Married',\n",
    "    2: 'Widowed',\n",
    "    3: 'Divorced',\n",
    "    4: 'Separated',\n",
    "    5: 'Never married'\n",
    "}\n",
    "\n",
    "df_analysis['marital_status'] = df_analysis['MAR'].map(mar_mapping)\n",
    "\n",
    "mar_dist = df_analysis.dropna(subset=['marital_status']).groupby(['marital_status', 'poverty_class']).size().unstack(fill_value=0)\n",
    "mar_dist = mar_dist[class_order]\n",
    "mar_dist_pct = mar_dist.div(mar_dist.sum(axis=1), axis=0) * 100\n",
    "\n",
    "# Sort by poverty rate\n",
    "vulnerable_rate = (mar_dist_pct['Deep Poverty'] + mar_dist_pct['Poverty'])\n",
    "mar_dist_pct = mar_dist_pct.loc[vulnerable_rate.sort_values(ascending=False).index]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Stacked bar chart\n",
    "mar_dist_pct.plot(kind='bar', stacked=True, ax=axes[0],\n",
    "                  color=[class_colors[c] for c in class_order], edgecolor='black', linewidth=0.5)\n",
    "axes[0].set_xlabel('Marital Status')\n",
    "axes[0].set_ylabel('Percentage (%)')\n",
    "axes[0].set_title('Poverty Class Distribution by Marital Status')\n",
    "axes[0].legend(title='Poverty Class', bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=30, ha='right')\n",
    "\n",
    "# Bar chart of vulnerable rates\n",
    "vulnerable_sorted = vulnerable_rate.sort_values(ascending=True)\n",
    "colors_gradient = plt.cm.RdYlGn(np.linspace(0.2, 0.8, len(vulnerable_sorted)))\n",
    "bars = axes[1].barh(range(len(vulnerable_sorted)), vulnerable_sorted.values, color=colors_gradient, edgecolor='black')\n",
    "axes[1].set_yticks(range(len(vulnerable_sorted)))\n",
    "axes[1].set_yticklabels(vulnerable_sorted.index)\n",
    "axes[1].set_xlabel('Below Poverty Line Rate (%)')\n",
    "axes[1].set_title('Poverty Rate by Marital Status')\n",
    "for bar, rate in zip(bars, vulnerable_sorted.values):\n",
    "    axes[1].text(bar.get_width() + 0.5, bar.get_y() + bar.get_height()/2,\n",
    "                 f'{rate:.1f}%', ha='left', va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('EDA_data/poverty_class_by_marital.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPoverty Rate by Marital Status:\")\n",
    "print(vulnerable_rate.sort_values(ascending=False).round(1).to_string())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "id39g0rh3mo",
   "metadata": {},
   "source": [
    "# Poverty Class Distribution by Citizenship Status (CIT)\n",
    "cit_mapping = {\n",
    "    1: 'Born in US',\n",
    "    2: 'Born in PR/US territories',\n",
    "    3: 'Born abroad (US parents)',\n",
    "    4: 'Naturalized citizen',\n",
    "    5: 'Not a citizen'\n",
    "}\n",
    "\n",
    "df_analysis['citizenship'] = df_analysis['CIT'].map(cit_mapping)\n",
    "\n",
    "cit_dist = df_analysis.dropna(subset=['citizenship']).groupby(['citizenship', 'poverty_class']).size().unstack(fill_value=0)\n",
    "cit_dist = cit_dist[class_order]\n",
    "cit_dist_pct = cit_dist.div(cit_dist.sum(axis=1), axis=0) * 100\n",
    "\n",
    "# Sort by poverty rate\n",
    "vulnerable_rate = (cit_dist_pct['Deep Poverty'] + cit_dist_pct['Poverty'])\n",
    "cit_dist_pct = cit_dist_pct.loc[vulnerable_rate.sort_values(ascending=False).index]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "cit_dist_pct.plot(kind='barh', stacked=True, ax=ax,\n",
    "                  color=[class_colors[c] for c in class_order], edgecolor='black', linewidth=0.5)\n",
    "ax.set_xlabel('Percentage (%)')\n",
    "ax.set_ylabel('Citizenship Status')\n",
    "ax.set_title('Poverty Class Distribution by Citizenship Status')\n",
    "ax.legend(title='Poverty Class', bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "\n",
    "# Add vulnerable rate labels\n",
    "for i, (idx, row) in enumerate(cit_dist_pct.iterrows()):\n",
    "    vuln = row['Deep Poverty'] + row['Poverty']\n",
    "    ax.text(102, i, f'{vuln:.1f}%', va='center', fontsize=10, fontweight='bold', color='#c0392b')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('EDA_data/poverty_class_by_citizenship.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPoverty Rate by Citizenship Status:\")\n",
    "print(vulnerable_rate.sort_values(ascending=False).round(1).to_string())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5wd5w9lgamx",
   "metadata": {},
   "source": [
    "# Intersectional Analysis: Age Group x Education Level\n",
    "# Create heatmap of poverty rates\n",
    "\n",
    "# Filter for adults only (working age)\n",
    "df_adults = df_analysis[(df_analysis['AGEP'] >= 25) & (df_analysis['AGEP'] <= 64)].copy()\n",
    "\n",
    "# Create simplified age groups for adults\n",
    "df_adults['adult_age_group'] = pd.cut(df_adults['AGEP'], \n",
    "                                       bins=[24, 34, 44, 54, 64],\n",
    "                                       labels=['25-34', '35-44', '45-54', '55-64'])\n",
    "\n",
    "# Calculate poverty rate for each intersection\n",
    "intersect_data = df_adults.groupby(['adult_age_group', 'education']).apply(\n",
    "    lambda x: (x['poverty_class'].isin(['Deep Poverty', 'Poverty'])).mean() * 100\n",
    ").unstack()\n",
    "\n",
    "# Reorder education\n",
    "edu_order = ['No HS Diploma', 'High School', 'Some College', \"Associate's\", \"Bachelor's\", \"Master's\", 'Professional/Doctorate']\n",
    "intersect_data = intersect_data[[c for c in edu_order if c in intersect_data.columns]]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.heatmap(intersect_data, annot=True, fmt='.1f', cmap='RdYlGn_r', \n",
    "            linewidths=0.5, ax=ax, cbar_kws={'label': 'Poverty Rate (%)'})\n",
    "ax.set_xlabel('Education Level')\n",
    "ax.set_ylabel('Age Group')\n",
    "ax.set_title('Poverty Rate (%) by Age and Education Level\\n(Working Age Adults 25-64)')\n",
    "plt.xticks(rotation=30, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig('EDA_data/poverty_heatmap_age_education.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPoverty Rate by Age x Education (%):\")\n",
    "print(intersect_data.round(1).to_string())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "33dbda2hq37",
   "metadata": {},
   "source": [
    "# Box Plots: POVPIP Distribution by Key Categories\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. POVPIP by Employment Status\n",
    "df_box = df_analysis.dropna(subset=['employment', 'POVPIP'])\n",
    "order = df_box.groupby('employment')['POVPIP'].median().sort_values().index\n",
    "sns.boxplot(data=df_box, x='employment', y='POVPIP', order=order, ax=axes[0, 0], palette='viridis')\n",
    "axes[0, 0].axhline(y=100, color='red', linestyle='--', label='Poverty line')\n",
    "axes[0, 0].set_xlabel('Employment Status')\n",
    "axes[0, 0].set_ylabel('POVPIP (Income-to-Poverty Ratio %)')\n",
    "axes[0, 0].set_title('POVPIP Distribution by Employment Status')\n",
    "axes[0, 0].tick_params(axis='x', rotation=30)\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# 2. POVPIP by Education Level\n",
    "df_box = df_analysis.dropna(subset=['education', 'POVPIP'])\n",
    "edu_order = ['No HS Diploma', 'High School', 'Some College', \"Associate's\", \"Bachelor's\", \"Master's\", 'Professional/Doctorate']\n",
    "sns.boxplot(data=df_box, x='education', y='POVPIP', order=edu_order, ax=axes[0, 1], palette='plasma')\n",
    "axes[0, 1].axhline(y=100, color='red', linestyle='--', label='Poverty line')\n",
    "axes[0, 1].set_xlabel('Education Level')\n",
    "axes[0, 1].set_ylabel('POVPIP (Income-to-Poverty Ratio %)')\n",
    "axes[0, 1].set_title('POVPIP Distribution by Education Level')\n",
    "axes[0, 1].tick_params(axis='x', rotation=30)\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# 3. POVPIP by Age Group\n",
    "df_box = df_analysis.dropna(subset=['age_group', 'POVPIP'])\n",
    "age_order = ['0-5', '6-18', '19-25', '26-35', '36-45', '46-55', '56-65', '65+']\n",
    "sns.boxplot(data=df_box, x='age_group', y='POVPIP', order=age_order, ax=axes[1, 0], palette='coolwarm')\n",
    "axes[1, 0].axhline(y=100, color='red', linestyle='--', label='Poverty line')\n",
    "axes[1, 0].set_xlabel('Age Group')\n",
    "axes[1, 0].set_ylabel('POVPIP (Income-to-Poverty Ratio %)')\n",
    "axes[1, 0].set_title('POVPIP Distribution by Age Group')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# 4. POVPIP by Disability Status\n",
    "df_box = df_analysis.dropna(subset=['disability', 'POVPIP'])\n",
    "sns.boxplot(data=df_box, x='disability', y='POVPIP', ax=axes[1, 1], palette='Set2')\n",
    "axes[1, 1].axhline(y=100, color='red', linestyle='--', label='Poverty line')\n",
    "axes[1, 1].set_xlabel('Disability Status')\n",
    "axes[1, 1].set_ylabel('POVPIP (Income-to-Poverty Ratio %)')\n",
    "axes[1, 1].set_title('POVPIP Distribution by Disability Status')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('EDA_data/povpip_boxplots.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "eda5tj8u8i4",
   "metadata": {},
   "source": [
    "# Violin Plots: POVPIP Distribution showing density\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# 1. POVPIP by Sex with violin plot\n",
    "df_violin = df_analysis.dropna(subset=['sex', 'POVPIP'])\n",
    "sns.violinplot(data=df_violin, x='sex', y='POVPIP', ax=axes[0], palette='Set1', inner='quartile')\n",
    "axes[0].axhline(y=100, color='red', linestyle='--', linewidth=2, label='Poverty line')\n",
    "axes[0].axhline(y=50, color='darkred', linestyle=':', linewidth=2, label='Deep poverty')\n",
    "axes[0].axhline(y=200, color='green', linestyle='--', linewidth=2, label='Stable threshold')\n",
    "axes[0].set_xlabel('Sex')\n",
    "axes[0].set_ylabel('POVPIP (Income-to-Poverty Ratio %)')\n",
    "axes[0].set_title('POVPIP Distribution by Sex (Violin Plot)')\n",
    "axes[0].legend()\n",
    "\n",
    "# 2. POVPIP by Hispanic Origin with violin plot\n",
    "df_violin = df_analysis.dropna(subset=['hispanic', 'POVPIP'])\n",
    "sns.violinplot(data=df_violin, x='hispanic', y='POVPIP', ax=axes[1], palette='Set2', inner='quartile')\n",
    "axes[1].axhline(y=100, color='red', linestyle='--', linewidth=2, label='Poverty line')\n",
    "axes[1].axhline(y=50, color='darkred', linestyle=':', linewidth=2, label='Deep poverty')\n",
    "axes[1].axhline(y=200, color='green', linestyle='--', linewidth=2, label='Stable threshold')\n",
    "axes[1].set_xlabel('Hispanic Origin')\n",
    "axes[1].set_ylabel('POVPIP (Income-to-Poverty Ratio %)')\n",
    "axes[1].set_title('POVPIP Distribution by Hispanic Origin (Violin Plot)')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('EDA_data/povpip_violinplots.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1onkn1u1glij",
   "metadata": {},
   "source": [
    "# Poverty by Language Spoken at Home (LANX)\n",
    "lanx_mapping = {1: 'English Only', 2: 'Other Language'}\n",
    "df_analysis['language'] = df_analysis['LANX'].map(lanx_mapping)\n",
    "\n",
    "lang_dist = df_analysis.dropna(subset=['language']).groupby(['language', 'poverty_class']).size().unstack(fill_value=0)\n",
    "lang_dist = lang_dist[class_order]\n",
    "lang_dist_pct = lang_dist.div(lang_dist.sum(axis=1), axis=0) * 100\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Stacked bar chart\n",
    "lang_dist_pct.plot(kind='bar', stacked=True, ax=axes[0],\n",
    "                   color=[class_colors[c] for c in class_order], edgecolor='black', linewidth=0.5)\n",
    "axes[0].set_xlabel('Language Spoken at Home')\n",
    "axes[0].set_ylabel('Percentage (%)')\n",
    "axes[0].set_title('Poverty Class Distribution by Language')\n",
    "axes[0].legend(title='Poverty Class')\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=0)\n",
    "\n",
    "# Comparison bar chart\n",
    "vulnerable_lang = lang_dist_pct['Deep Poverty'] + lang_dist_pct['Poverty']\n",
    "colors_bar = ['#3498db', '#e74c3c']\n",
    "bars = axes[1].bar(vulnerable_lang.index, vulnerable_lang.values, color=colors_bar, edgecolor='black')\n",
    "axes[1].set_ylabel('Below Poverty Line Rate (%)')\n",
    "axes[1].set_title('Poverty Rate by Language at Home')\n",
    "axes[1].set_ylim(0, max(vulnerable_lang.values) * 1.3)\n",
    "\n",
    "for bar, rate in zip(bars, vulnerable_lang.values):\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
    "                 f'{rate:.1f}%', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('EDA_data/poverty_class_by_language.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nPoverty Rate by Language:\")\n",
    "for lang, rate in vulnerable_lang.items():\n",
    "    print(f\"  {lang}: {rate:.1f}%\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bvx69ykauyh",
   "metadata": {},
   "source": [
    "# Summary: Risk Factor Comparison Chart\n",
    "# Calculate poverty rates for key binary/categorical risk factors\n",
    "\n",
    "risk_factors = []\n",
    "\n",
    "# Disability\n",
    "has_dis = df_analysis[df_analysis['DIS'] == 1]['poverty_class'].isin(['Deep Poverty', 'Poverty']).mean() * 100\n",
    "no_dis = df_analysis[df_analysis['DIS'] == 2]['poverty_class'].isin(['Deep Poverty', 'Poverty']).mean() * 100\n",
    "risk_factors.append({'Factor': 'Has Disability', 'Rate': has_dis, 'Baseline': no_dis})\n",
    "\n",
    "# No Health Insurance\n",
    "no_ins = df_analysis[df_analysis['HICOV'] == 2]['poverty_class'].isin(['Deep Poverty', 'Poverty']).mean() * 100\n",
    "has_ins = df_analysis[df_analysis['HICOV'] == 1]['poverty_class'].isin(['Deep Poverty', 'Poverty']).mean() * 100\n",
    "risk_factors.append({'Factor': 'No Health Insurance', 'Rate': no_ins, 'Baseline': has_ins})\n",
    "\n",
    "# Unemployed\n",
    "unemployed = df_analysis[df_analysis['ESR'] == 3]['poverty_class'].isin(['Deep Poverty', 'Poverty']).mean() * 100\n",
    "employed = df_analysis[df_analysis['ESR'].isin([1, 2])]['poverty_class'].isin(['Deep Poverty', 'Poverty']).mean() * 100\n",
    "risk_factors.append({'Factor': 'Unemployed', 'Rate': unemployed, 'Baseline': employed})\n",
    "\n",
    "# No HS Diploma\n",
    "no_hs = df_analysis[df_analysis['education'] == 'No HS Diploma']['poverty_class'].isin(['Deep Poverty', 'Poverty']).mean() * 100\n",
    "has_hs = df_analysis[df_analysis['education'] != 'No HS Diploma']['poverty_class'].isin(['Deep Poverty', 'Poverty']).mean() * 100\n",
    "risk_factors.append({'Factor': 'No HS Diploma', 'Rate': no_hs, 'Baseline': has_hs})\n",
    "\n",
    "# Not a Citizen\n",
    "not_cit = df_analysis[df_analysis['CIT'] == 5]['poverty_class'].isin(['Deep Poverty', 'Poverty']).mean() * 100\n",
    "is_cit = df_analysis[df_analysis['CIT'] != 5]['poverty_class'].isin(['Deep Poverty', 'Poverty']).mean() * 100\n",
    "risk_factors.append({'Factor': 'Not a Citizen', 'Rate': not_cit, 'Baseline': is_cit})\n",
    "\n",
    "# Other Language at Home\n",
    "other_lang = df_analysis[df_analysis['LANX'] == 2]['poverty_class'].isin(['Deep Poverty', 'Poverty']).mean() * 100\n",
    "english = df_analysis[df_analysis['LANX'] == 1]['poverty_class'].isin(['Deep Poverty', 'Poverty']).mean() * 100\n",
    "risk_factors.append({'Factor': 'Non-English at Home', 'Rate': other_lang, 'Baseline': english})\n",
    "\n",
    "# Never Married (adults 25+)\n",
    "never_mar = df_analysis[(df_analysis['MAR'] == 5) & (df_analysis['AGEP'] >= 25)]['poverty_class'].isin(['Deep Poverty', 'Poverty']).mean() * 100\n",
    "married = df_analysis[(df_analysis['MAR'] == 1) & (df_analysis['AGEP'] >= 25)]['poverty_class'].isin(['Deep Poverty', 'Poverty']).mean() * 100\n",
    "risk_factors.append({'Factor': 'Never Married (25+)', 'Rate': never_mar, 'Baseline': married})\n",
    "\n",
    "rf_df = pd.DataFrame(risk_factors)\n",
    "rf_df['Difference'] = rf_df['Rate'] - rf_df['Baseline']\n",
    "rf_df = rf_df.sort_values('Rate', ascending=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Create horizontal bar chart\n",
    "y_pos = range(len(rf_df))\n",
    "bars = ax.barh(y_pos, rf_df['Rate'], color='#c0392b', edgecolor='black', label='Risk Group', height=0.4)\n",
    "bars2 = ax.barh([y + 0.4 for y in y_pos], rf_df['Baseline'], color='#27ae60', edgecolor='black', \n",
    "                label='Comparison Group', height=0.4, alpha=0.7)\n",
    "\n",
    "ax.set_yticks([y + 0.2 for y in y_pos])\n",
    "ax.set_yticklabels(rf_df['Factor'])\n",
    "ax.set_xlabel('Poverty Rate (%)')\n",
    "ax.set_title('Poverty Risk Factors: Comparing At-Risk vs Reference Groups', fontsize=12)\n",
    "ax.legend(loc='lower right')\n",
    "\n",
    "# Add rate labels\n",
    "for i, (idx, row) in enumerate(rf_df.iterrows()):\n",
    "    ax.text(row['Rate'] + 0.5, i, f'{row[\"Rate\"]:.1f}%', va='center', fontsize=9, color='#c0392b', fontweight='bold')\n",
    "    ax.text(row['Baseline'] + 0.5, i + 0.4, f'{row[\"Baseline\"]:.1f}%', va='center', fontsize=9, color='#27ae60')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('EDA_data/poverty_risk_factors_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== Poverty Risk Factor Summary ===\")\n",
    "print(f\"{'Factor':<25} {'At-Risk':>10} {'Baseline':>10} {'Difference':>12}\")\n",
    "print(\"-\" * 60)\n",
    "for _, row in rf_df.sort_values('Difference', ascending=False).iterrows():\n",
    "    print(f\"{row['Factor']:<25} {row['Rate']:>9.1f}% {row['Baseline']:>9.1f}% {row['Difference']:>+11.1f}%\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ivkwp2fipha",
   "metadata": {},
   "source": [
    "# Population Pyramid: Age Distribution by Sex and Poverty Status\n",
    "df_pyramid = df_analysis.dropna(subset=['age_group', 'sex', 'poverty_class']).copy()\n",
    "\n",
    "# Create vulnerable indicator\n",
    "df_pyramid['vulnerable'] = df_pyramid['poverty_class'].isin(['Deep Poverty', 'Poverty'])\n",
    "\n",
    "age_order = ['0-5', '6-18', '19-25', '26-35', '36-45', '46-55', '56-65', '65+']\n",
    "\n",
    "# Calculate counts by age, sex, and vulnerability\n",
    "pyramid_data = df_pyramid.groupby(['age_group', 'sex', 'vulnerable']).size().unstack(fill_value=0)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# Left side: Male\n",
    "male_data = df_pyramid[df_pyramid['sex'] == 'Male'].groupby('age_group')['vulnerable'].value_counts(normalize=True).unstack(fill_value=0) * 100\n",
    "male_data = male_data.reindex(age_order)\n",
    "\n",
    "# Right side: Female\n",
    "female_data = df_pyramid[df_pyramid['sex'] == 'Female'].groupby('age_group')['vulnerable'].value_counts(normalize=True).unstack(fill_value=0) * 100\n",
    "female_data = female_data.reindex(age_order)\n",
    "\n",
    "# Plot Male (left, reversed)\n",
    "y_pos = range(len(age_order))\n",
    "axes[0].barh(y_pos, -male_data[True], color='#c0392b', label='Below Poverty', edgecolor='black')\n",
    "axes[0].barh(y_pos, -male_data[False], left=-male_data[True], color='#3498db', label='Above Poverty', edgecolor='black', alpha=0.7)\n",
    "axes[0].set_yticks(y_pos)\n",
    "axes[0].set_yticklabels(age_order)\n",
    "axes[0].set_xlabel('Percentage (%)')\n",
    "axes[0].set_title('Male', fontsize=14)\n",
    "axes[0].set_xlim(-100, 0)\n",
    "axes[0].invert_xaxis()\n",
    "axes[0].legend(loc='lower left')\n",
    "\n",
    "# Plot Female (right)\n",
    "axes[1].barh(y_pos, female_data[True], color='#c0392b', label='Below Poverty', edgecolor='black')\n",
    "axes[1].barh(y_pos, female_data[False], left=female_data[True], color='#e91e63', label='Above Poverty', edgecolor='black', alpha=0.7)\n",
    "axes[1].set_yticks(y_pos)\n",
    "axes[1].set_yticklabels([])\n",
    "axes[1].set_xlabel('Percentage (%)')\n",
    "axes[1].set_title('Female', fontsize=14)\n",
    "axes[1].set_xlim(0, 100)\n",
    "axes[1].legend(loc='lower right')\n",
    "\n",
    "fig.suptitle('Poverty Status by Age and Sex\\n(Percentage within each Age-Sex group)', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('EDA_data/poverty_pyramid_age_sex.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPoverty Rate by Age and Sex:\")\n",
    "print(\"\\nMale:\")\n",
    "print((male_data[True]).round(1).to_string())\n",
    "print(\"\\nFemale:\")\n",
    "print((female_data[True]).round(1).to_string())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4y4ltwrwxvx",
   "metadata": {},
   "source": [
    "# Sample Size Overview: Class Breakdown with Counts\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# 1. Donut chart of poverty class distribution\n",
    "class_counts = df_analysis['poverty_class'].value_counts().reindex(class_order)\n",
    "colors = [class_colors[c] for c in class_order]\n",
    "\n",
    "wedges, texts, autotexts = axes[0].pie(class_counts.values, labels=None, autopct='', \n",
    "                                        colors=colors, startangle=90, \n",
    "                                        wedgeprops=dict(width=0.5, edgecolor='white'))\n",
    "\n",
    "# Add center text\n",
    "total = class_counts.sum()\n",
    "axes[0].text(0, 0, f'Total\\n{total:,}', ha='center', va='center', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Custom legend with counts and percentages\n",
    "legend_labels = [f'{cls}: {cnt:,} ({cnt/total*100:.1f}%)' for cls, cnt in zip(class_order, class_counts.values)]\n",
    "axes[0].legend(wedges, legend_labels, title='Poverty Class', loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "axes[0].set_title('Sample Distribution by Poverty Class', fontsize=12)\n",
    "\n",
    "# 2. Treemap-style breakdown\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# Prepare data for treemap\n",
    "class_data = pd.DataFrame({\n",
    "    'Class': class_order,\n",
    "    'Count': class_counts.values,\n",
    "    'Pct': class_counts.values / total * 100\n",
    "})\n",
    "\n",
    "# Simple stacked bar to show proportions\n",
    "bottom = 0\n",
    "for i, row in class_data.iterrows():\n",
    "    rect_height = row['Pct']\n",
    "    axes[1].add_patch(Rectangle((0, bottom), 1, rect_height, \n",
    "                                  facecolor=class_colors[row['Class']], \n",
    "                                  edgecolor='white', linewidth=2))\n",
    "    # Add label\n",
    "    if rect_height > 5:  # Only label if big enough\n",
    "        axes[1].text(0.5, bottom + rect_height/2, \n",
    "                     f\"{row['Class']}\\n{row['Count']:,}\\n({row['Pct']:.1f}%)\", \n",
    "                     ha='center', va='center', fontsize=10, fontweight='bold',\n",
    "                     color='white' if row['Class'] in ['Deep Poverty', 'Poverty'] else 'black')\n",
    "    bottom += rect_height\n",
    "\n",
    "axes[1].set_xlim(0, 1)\n",
    "axes[1].set_ylim(0, 100)\n",
    "axes[1].axis('off')\n",
    "axes[1].set_title('Proportional Breakdown of Poverty Classes', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('EDA_data/poverty_class_breakdown.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== Sample Size Summary ===\")\n",
    "print(f\"Total records with valid POVPIP: {total:,}\")\n",
    "print(\"\\nBreakdown by poverty class:\")\n",
    "for cls in class_order:\n",
    "    cnt = class_counts[cls]\n",
    "    pct = cnt / total * 100\n",
    "    print(f\"  {cls:<15}: {cnt:>10,} ({pct:>5.1f}%)\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a2de5d13-71e6-4ccd-8cde-1268501ea84d",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
