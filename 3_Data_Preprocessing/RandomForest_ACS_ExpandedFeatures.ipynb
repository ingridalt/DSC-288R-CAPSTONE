{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6c57c58",
   "metadata": {},
   "source": [
    "# Random Forest (Expanded Features) â€” ACS Poverty Risk\n",
    "\n",
    "This notebook implements:\n",
    "- Expanded feature set beyond the baseline logistic regression (adds MAR/MSP/NATIVITY/WRK/WKL/ENG/LANP/PUMA/POBP and engineered flags)\n",
    "- Uses `ColumnTransformer` + `OneHotEncoder(sparse_output=True)`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7175b4d-3fd3-4064-bdee-d5dc25d8b7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "-- correcting class imablance in RF --class_weight tuning \"balance_subsample\"?\n",
    "-- explore features outside of LR model\n",
    "-- variable mapping\n",
    "-- verify null handling for each\n",
    "-- RC related child variable might be all NaN bc it is N/A to our people. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef5f66fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7111df84",
   "metadata": {},
   "source": [
    "## 1) Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5cf460e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1469769, 27)\n",
      "Test shape : (304368, 108)\n",
      "\n",
      "Train target distribution:\n",
      "poverty_risk_score\n",
      "0.0    1114746\n",
      "1.0     196583\n",
      "3.0      79445\n",
      "2.0      78995\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_path = \"preprocessing_data/train_data_final_feat_no_preprocessing.csv\"\n",
    "test_path  = \"preprocessing_data/test_data_final_feat_no_preprocessing.csv\"\n",
    "\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_test  = pd.read_csv(test_path)\n",
    "\n",
    "print(\"Train shape:\", df_train.shape)\n",
    "print(\"Test shape :\", df_test.shape)\n",
    "print(\"\\nTrain target distribution:\")\n",
    "print(df_train[\"poverty_risk_score\"].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec38acd2-409e-4143-a68c-abdaf30f4160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_acs_nas(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    df[\"WKHP\"] = df[\"WKHP\"].replace({0: np.nan})\n",
    "    df[\"WKL\"]  = df[\"WKL\"].replace({0: np.nan})\n",
    "    df[\"WRK\"]  = df[\"WRK\"].map({1:1, 2:0, 0:np.nan})\n",
    "    df[\"LANX\"] = df[\"LANX\"].map({1:1, 2:0, 0:np.nan})\n",
    "    df[\"ENG\"]  = df[\"ENG\"].replace({0: np.nan})\n",
    "    df[\"MIG\"]  = df[\"MIG\"].replace({0: np.nan})\n",
    "    df.loc[df[\"AGEP\"] < 15, \"MAR\"] = np.nan\n",
    "\n",
    "    #handling nulls\n",
    "\n",
    "    for c in [\"WKHP\", \"WKL\", \"ENG\", \"LANX\", \"MIG\", \"WRK\"]:\n",
    "        if c in df.columns:\n",
    "            df[f\"{c}_missing\"] = df[c].isna().astype(int)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8dd60588-8c44-4aee-9aa7-c3a1ec88e842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ENG         57.57\n",
       "WKHP        35.11\n",
       "OCCP        25.64\n",
       "WRK         11.47\n",
       "LANX         0.00\n",
       "MIG          0.00\n",
       "PUMA         0.00\n",
       "POBP         0.00\n",
       "WKL          0.00\n",
       "SCHL         0.00\n",
       "ESR          0.00\n",
       "CIT          0.00\n",
       "MAR          0.00\n",
       "MSP          0.00\n",
       "NATIVITY     0.00\n",
       "RAC1P        0.00\n",
       "year         0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for nulls\n",
    "cols = [\"WKHP\",\"WKL\",\"WRK\",\"ENG\",\"LANX\",\"MIG\",\"PUMA\",\"POBP\",\"OCCP\",\"SCHL\",\"ESR\",\"CIT\",\"MAR\",\"MSP\",\"NATIVITY\",\"RAC1P\",\"year\"]\n",
    "(df_train[cols].isna().mean().sort_values(ascending=False) * 100).round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab37d86b-7b28-4600-bcdb-70e61bcb83ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1469769, 33)\n",
      "Test shape : (304368, 114)\n",
      "\n",
      "Train target distribution:\n",
      "poverty_risk_score\n",
      "0.0    1114746\n",
      "1.0     196583\n",
      "3.0      79445\n",
      "2.0      78995\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# fix ACS\n",
    "df_train = fix_acs_nas(df_train)\n",
    "df_test  = fix_acs_nas(df_test)\n",
    "\n",
    "print(\"Train shape:\", df_train.shape)\n",
    "print(\"Test shape :\", df_test.shape)\n",
    "print(\"\\nTrain target distribution:\")\n",
    "print(df_train[\"poverty_risk_score\"].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc471b0",
   "metadata": {},
   "source": [
    "## 2) Preprocessing function (expanded features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54e2c0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_acs_data_rf(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Preprocess ACS-like features for Random Forest.\n",
    "    - Do NOT fill binary columns with 0 (0 can be meaningful).\n",
    "    - Map {1,2} survey binaries -> {1,0} while leaving NaN as NaN.\n",
    "    - Keep full OCCP (no top-10 grouping).\n",
    "    - Keep correlated features (RF doesn't require multicollinearity pruning).\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    mapping_12 = {1: 1, 2: 0}  # 1=yes, 2=no\n",
    "\n",
    "    # Insurance + disability + sex\n",
    "    for col in [\"PRIVCOV\", \"PUBCOV\", \"DIS\", \"SEX\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].map(mapping_12)\n",
    "\n",
    "    # HICOV: {1:0, 2:1} (2 indicates \"No insurance\")\n",
    "    if \"HICOV\" in df.columns:\n",
    "        df[\"HICOV\"] = df[\"HICOV\"].map({1: 0, 2: 1})\n",
    "\n",
    "    # MAR: only explicit 1 is \"married\"; preserve NaN\n",
    "    if \"MAR\" in df.columns:\n",
    "        df[\"MAR\"] = np.where(df[\"MAR\"].isna(), np.nan, (df[\"MAR\"] == 1).astype(int))\n",
    "\n",
    "    # Citizenship -> binary flag; preserve NaN\n",
    "    if \"CIT\" in df.columns:\n",
    "        df[\"CIT\"] = np.where(df[\"CIT\"].isna(), np.nan, (df[\"CIT\"] < 5).astype(int))\n",
    "\n",
    "    # Employment status flag from ESR\n",
    "    if \"ESR\" in df.columns:\n",
    "        df[\"ESR_emp\"] = np.where(df[\"ESR\"].isna(), np.nan, df[\"ESR\"].isin([1, 2]).astype(int))\n",
    "\n",
    "    # Worked last week (often 1=yes,2=no)\n",
    "    if \"WRK\" in df.columns:\n",
    "        df[\"WRK\"] = df[\"WRK\"].map(mapping_12)\n",
    "\n",
    "    # MIG recent move flag\n",
    "    if \"MIG\" in df.columns:\n",
    "        df[\"MIG_recent\"] = np.where(df[\"MIG\"].isna(), np.nan, df[\"MIG\"].isin([2, 3]).astype(int))\n",
    "\n",
    "    # NATIVITY: commonly 1=native,2=foreign born (confirm for your extract)\n",
    "    if \"NATIVITY\" in df.columns:\n",
    "        df[\"ForeignBorn\"] = df[\"NATIVITY\"].map({1: 0, 2: 1})\n",
    "\n",
    "    # Place of birth: keep POBP and engineer Born_in_CA\n",
    "    if \"POBP\" in df.columns:\n",
    "        df[\"Born_in_CA\"] = np.where(df[\"POBP\"].isna(), np.nan, (df[\"POBP\"] == 6).astype(int))\n",
    "\n",
    "    # Language\n",
    "    if \"LANX\" in df.columns:\n",
    "        df[\"LANX\"] = np.where(df[\"LANX\"].isna(), np.nan, (df[\"LANX\"] == 1).astype(int))\n",
    "\n",
    "    # Education tiers\n",
    "    if \"SCHL\" in df.columns:\n",
    "        def recode_education(val):\n",
    "            if pd.isna(val) or val <= 15: return 0\n",
    "            if val <= 17: return 1\n",
    "            if val <= 20: return 2\n",
    "            return 3\n",
    "        df[\"SCHL_Tier\"] = df[\"SCHL\"].apply(recode_education)\n",
    "\n",
    "    # Cast selected categoricals to string (later coerced to object+None for sklearn)\n",
    "    for cat_col in [\"OCCP\", \"CA_Region\", \"RAC1P\", \"year\", \"MSP\", \"WKL\", \"ENG\", \"LANP\", \"PUMA\", \"POBP\"]:\n",
    "        if cat_col in df.columns:\n",
    "            df[cat_col] = df[cat_col].astype(\"string\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce2631fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done preprocessing.\n"
     ]
    }
   ],
   "source": [
    "df_train_pp = preprocess_acs_data_rf(df_train)\n",
    "df_test_pp  = preprocess_acs_data_rf(df_test)\n",
    "\n",
    "print(\"Done preprocessing.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f51701",
   "metadata": {},
   "source": [
    "## 3) Feature set (expanded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc2255a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train raw: (1469769, 23) X_test raw: (304368, 23)\n"
     ]
    }
   ],
   "source": [
    "features = [\n",
    "    # numeric-ish\n",
    "    \"AGEP\", \"WKHP\", \"SCHL_Tier\",\n",
    "\n",
    "    # binaries\n",
    "    \"SEX\", \"DIS\", \"CIT\", \"MAR\", \"WRK\", \"Born_in_CA\", \"LANX\", \"ForeignBorn\", \"ESR_emp\", \"MIG_recent\",\n",
    "\n",
    "    # categoricals\n",
    "    \"MSP\", \"WKL\", \"ENG\", \"LANP\",\n",
    "    \"OCCP\", \"RAC1P\", \"CA_Region\",\n",
    "    \"PUMA\", \"POBP\",\n",
    "    \"year\"\n",
    "]\n",
    "\n",
    "target_col = \"poverty_risk_score\"\n",
    "\n",
    "missing = [c for c in features + [target_col] if c not in df_train_pp.columns]\n",
    "if missing:\n",
    "    print(\"WARNING missing columns:\", missing)\n",
    "\n",
    "# split for ColumnTransformer\n",
    "num_features = [\"AGEP\", \"WKHP\", \"SCHL_Tier\"]\n",
    "bin_features = [\"SEX\",\"DIS\",\"CIT\",\"MAR\",\"WRK\",\"Born_in_CA\",\"LANX\",\"ForeignBorn\",\"ESR_emp\",\"MIG_recent\"]\n",
    "cat_features = [\"MSP\",\"WKL\",\"ENG\",\"LANP\",\"OCCP\",\"RAC1P\",\"CA_Region\",\"PUMA\",\"POBP\",\"year\"]\n",
    "\n",
    "X_train = df_train_pp[features].copy()\n",
    "X_test  = df_test_pp[features].copy()\n",
    "y_train = df_train_pp[target_col].astype(int)\n",
    "y_test  = df_test_pp[target_col].astype(int)\n",
    "\n",
    "print(\"X_train raw:\", X_train.shape, \"X_test raw:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94daaae",
   "metadata": {},
   "source": [
    "## 4) Fix pandas nullable missing + build sparse preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ddbd654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_sparse: (1469769, 1266) <class 'scipy.sparse._csr.csr_matrix'>\n",
      "X_test_sparse : (304368, 1266) <class 'scipy.sparse._csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "# sklearn doesn't like pandas pd.NA in object-like columns.\n",
    "# Make numerics real numeric and categoricals plain objects with None for missing.\n",
    "\n",
    "for c in num_features + bin_features:\n",
    "    X_train[c] = pd.to_numeric(X_train[c], errors=\"coerce\")\n",
    "    X_test[c]  = pd.to_numeric(X_test[c], errors=\"coerce\")\n",
    "\n",
    "for c in cat_features:\n",
    "    X_train[c] = X_train[c].astype(\"object\")\n",
    "    X_test[c]  = X_test[c].astype(\"object\")\n",
    "    X_train[c] = X_train[c].where(pd.notna(X_train[c]), None)\n",
    "    X_test[c]  = X_test[c].where(pd.notna(X_test[c]), None)\n",
    "\n",
    "# Buckets rare categories into an 'infrequent' bin to keep feature space manageable.\n",
    "MIN_FREQ = 25  # try 5/25/50 depending on runtime/memory\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", SimpleImputer(strategy=\"median\"), num_features),\n",
    "        (\"bin\", SimpleImputer(strategy=\"most_frequent\"), bin_features),\n",
    "        (\"cat\", Pipeline(steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"ohe\", OneHotEncoder(\n",
    "                handle_unknown=\"ignore\",\n",
    "                sparse_output=True,\n",
    "                min_frequency=MIN_FREQ\n",
    "            ))\n",
    "        ]), cat_features),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "X_train_sparse = preprocess.fit_transform(X_train)\n",
    "X_test_sparse  = preprocess.transform(X_test)\n",
    "\n",
    "print(\"X_train_sparse:\", X_train_sparse.shape, type(X_train_sparse))\n",
    "print(\"X_test_sparse :\", X_test_sparse.shape, type(X_test_sparse))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c422ce",
   "metadata": {},
   "source": [
    "## 5) Train Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c011619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Random Forest Performance ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.66      0.77    233793\n",
      "           1       0.23      0.41      0.30     38456\n",
      "           2       0.15      0.25      0.19     15534\n",
      "           3       0.23      0.58      0.33     16585\n",
      "\n",
      "    accuracy                           0.61    304368\n",
      "   macro avg       0.38      0.48      0.40    304368\n",
      "weighted avg       0.76      0.61      0.66    304368\n",
      "\n",
      "Confusion matrix:\n",
      "[[155335  44553  12848  21057]\n",
      " [  9153  15830   5960   7513]\n",
      " [  2540   4640   3912   4442]\n",
      " [  1803   2448   2708   9626]]\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    min_samples_split=20,\n",
    "    min_samples_leaf=10,\n",
    "    class_weight=\"balanced_subsample\", # set to account for class imbalance in povpip\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf.fit(X_train_sparse, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test_sparse)\n",
    "\n",
    "print(\"=== Random Forest Performance ===\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76462e9",
   "metadata": {},
   "source": [
    "## 6) Optional: inspect cardinality for big categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022ef8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in [\"PUMA\", \"POBP\", \"LANP\"]:\n",
    "    if c in df_train_pp.columns:\n",
    "        print(c, \"nunique:\", df_train_pp[c].nunique(dropna=True))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
