{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6c57c58",
   "metadata": {},
   "source": [
    "# Random Forest (Expanded Features) — Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef5f66fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7111df84",
   "metadata": {},
   "source": [
    "## 1) Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5cf460e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1469769, 27)\n",
      "Test shape : (304368, 27)\n",
      "\n",
      "Train target distribution:\n",
      "poverty_risk_score\n",
      "0.0    1114746\n",
      "1.0     196583\n",
      "3.0      79445\n",
      "2.0      78995\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_path = \"preprocessing_data/train_data_final_feat_no_preprocessing.csv\"\n",
    "test_path  = \"preprocessing_data/test_data_final_feat_no_preprocessing.csv\"\n",
    "\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_test  = pd.read_csv(test_path)\n",
    "\n",
    "print(\"Train shape:\", df_train.shape)\n",
    "print(\"Test shape :\", df_test.shape)\n",
    "print(\"\\nTrain target distribution:\")\n",
    "print(df_train[\"poverty_risk_score\"].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dd60588-8c44-4aee-9aa7-c3a1ec88e842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ENG         57.57\n",
       "WKHP        35.11\n",
       "OCCP        25.64\n",
       "WRK         11.47\n",
       "LANX         0.00\n",
       "MIG          0.00\n",
       "PUMA         0.00\n",
       "POBP         0.00\n",
       "WKL          0.00\n",
       "SCHL         0.00\n",
       "ESR          0.00\n",
       "CIT          0.00\n",
       "MAR          0.00\n",
       "MSP          0.00\n",
       "NATIVITY     0.00\n",
       "RAC1P        0.00\n",
       "year         0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for nulls\n",
    "cols = [\"WKHP\",\"WKL\",\"WRK\",\"ENG\",\"LANX\",\"MIG\",\"PUMA\",\"POBP\",\"OCCP\",\"SCHL\",\"ESR\",\"CIT\",\"MAR\",\"MSP\",\"NATIVITY\",\"RAC1P\",\"year\"]\n",
    "(df_train[cols].isna().mean().sort_values(ascending=False) * 100).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe3907b4-4d91-42c0-83b3-a56f1c2e957c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ENG\n",
       "NaN    846170\n",
       "1.0    347613\n",
       "2.0    132583\n",
       "3.0     99738\n",
       "4.0     43665\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check value counts for the english speaking variable\n",
    "df_train[\"ENG\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec38acd2-409e-4143-a68c-abdaf30f4160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_acs_nas(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    df[\"WKHP\"] = df[\"WKHP\"].replace({0: np.nan})\n",
    "    df[\"WKL\"]  = df[\"WKL\"].replace({0: np.nan})\n",
    "    df[\"WRK\"]  = df[\"WRK\"].map({1:1, 2:0, 0:np.nan})\n",
    "    df[\"LANX\"] = df[\"LANX\"].map({1:1, 2:0, 0:np.nan})\n",
    "    df.loc[(df[\"ENG\"].isna()) & (df[\"LANX\"] == 0), \"ENG\"] = 0\n",
    "\n",
    "    #df[\"ENG\"]  = df[\"ENG\"].replace({0: np.nan}) -- see below note and code on ENG variable.\n",
    "    df[\"MIG\"]  = df[\"MIG\"].replace({0: np.nan})\n",
    "    df[\"ESR\"] = df[\"ESR\"].replace({0: np.nan})\n",
    "    # MAR: not applicable under 15\n",
    "    df.loc[df[\"AGEP\"] < 15, \"MAR\"] = np.nan\n",
    "    # MSP: not applicable under 15\n",
    "    df.loc[df[\"AGEP\"] < 15, \"MSP\"] = np.nan\n",
    "\n",
    "\n",
    "    #handling nulls\n",
    "\n",
    "    for c in [\"WKHP\", \"WKL\", \"ENG\", \"LANX\", \"MIG\", \"WRK\"]:\n",
    "        if c in df.columns:\n",
    "            df[f\"{c}_missing\"] = df[c].isna().astype(int)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be3de931-2920-43cf-9b75-19d312285d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ENG = 0 → speaks only English\\nENG = 1–4 → proficiency\\nENG_missing now represents true unexpected missingness'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_fixed = fix_acs_nas(df_train)\n",
    "\n",
    "df_fixed[\"ENG_missing\"].value_counts(dropna=False)\n",
    "df_fixed[\"ENG\"].isna().mean()\n",
    "df_fixed[\"ENG\"].value_counts(dropna=False).head(10)\n",
    "\n",
    "'''ENG = 0 → speaks only English\n",
    "ENG = 1–4 → proficiency\n",
    "ENG_missing now represents true unexpected missingness'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab37d86b-7b28-4600-bcdb-70e61bcb83ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1469769, 33)\n",
      "Test shape : (304368, 33)\n",
      "\n",
      "Train target distribution:\n",
      "poverty_risk_score\n",
      "0.0    1114746\n",
      "1.0     196583\n",
      "3.0      79445\n",
      "2.0      78995\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# fix ACS with mapped values for variables\n",
    "df_train = fix_acs_nas(df_train)\n",
    "df_test  = fix_acs_nas(df_test)\n",
    "\n",
    "print(\"Train shape:\", df_train.shape)\n",
    "print(\"Test shape :\", df_test.shape)\n",
    "print(\"\\nTrain target distribution:\")\n",
    "print(df_train[\"poverty_risk_score\"].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc471b0",
   "metadata": {},
   "source": [
    "## 2) Preprocessing function (expanded features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54e2c0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_acs_data_rf(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Preprocess ACS-like features for Random Forest.\n",
    "    - Do NOT fill binary columns with 0 (0 can be meaningful).\n",
    "    - Map {1,2} survey binaries -> {1,0} while leaving NaN as NaN.\n",
    "    - Keep full OCCP (no top-10 grouping).\n",
    "    - Keep correlated features (RF doesn't require multicollinearity pruning).\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    mapping_12 = {1: 1, 2: 0}  # 1=yes, 2=no\n",
    "\n",
    "    #Insurance, disability, sex\n",
    "    for col in [\"PRIVCOV\", \"PUBCOV\", \"DIS\", \"SEX\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].map(mapping_12)\n",
    "\n",
    "    #HICOV:{1:0, 2:1} (2 indicates \"no insuranc\")\n",
    "    if \"HICOV\" in df.columns:\n",
    "        df[\"HICOV\"] = df[\"HICOV\"].map({1: 0, 2: 1})\n",
    "\n",
    "    #MAR:only explicit 1 is \"married\"; preserve NaN\n",
    "    if \"MAR\" in df.columns:\n",
    "        df[\"MAR\"] = np.where(df[\"MAR\"].isna(), np.nan, (df[\"MAR\"] == 1).astype(int))\n",
    "\n",
    "    #citizenship binary flag/preserve NaN\n",
    "    if \"CIT\" in df.columns:\n",
    "        df[\"CIT\"] = np.where(df[\"CIT\"].isna(), np.nan, (df[\"CIT\"] < 5).astype(int))\n",
    "\n",
    "    #employment status flag from ESR\n",
    "    if \"ESR\" in df.columns:\n",
    "        df[\"ESR_emp\"] = np.where(df[\"ESR\"].isna(), np.nan, df[\"ESR\"].isin([1, 2]).astype(int))\n",
    "\n",
    "    # worked last week (1=yes,2=no)\n",
    "    if \"WRK\" in df.columns:\n",
    "        df[\"WRK\"] = df[\"WRK\"].map(mapping_12)\n",
    "\n",
    "    #MIG recent move flag\n",
    "    if \"MIG\" in df.columns:\n",
    "        df[\"MIG_recent\"] = np.where(df[\"MIG\"].isna(), np.nan, df[\"MIG\"].isin([2, 3]).astype(int))\n",
    "\n",
    "    #NATIVITY: 1=native,2=foreign born\n",
    "    if \"NATIVITY\" in df.columns:\n",
    "        df[\"ForeignBorn\"] = df[\"NATIVITY\"].map({1: 0, 2: 1})\n",
    "\n",
    "    #place ofbirth: keep POBP/engineer Born_in_CA\n",
    "    if \"POBP\" in df.columns:\n",
    "        df[\"Born_in_CA\"] = np.where(df[\"POBP\"].isna(), np.nan, (df[\"POBP\"] == 6).astype(int))\n",
    "\n",
    "    #Language\n",
    "    if \"LANX\" in df.columns:\n",
    "        df[\"LANX\"] = np.where(df[\"LANX\"].isna(), np.nan, (df[\"LANX\"] == 1).astype(int))\n",
    "\n",
    "    #Educationtiers\n",
    "    if \"SCHL\" in df.columns:\n",
    "        def recode_education(val):\n",
    "            if pd.isna(val) or val == 0:\n",
    "                return np.nan   # 0 = N/A (<3 years old)\n",
    "            if val <= 15:\n",
    "                return 0\n",
    "            if val <= 17:\n",
    "                return 1\n",
    "            if val <= 20:\n",
    "                return 2\n",
    "            return 3\n",
    "\n",
    "        df[\"SCHL_Tier\"] = df[\"SCHL\"].apply(recode_education)\n",
    "\n",
    "    # Cast selected categoricals to string (later coerced to object+None for sklearn)\n",
    "    for cat_col in [\"OCCP\", \"CA_Region\", \"RAC1P\", \"year\", \"MSP\", \"WKL\", \"ENG\", \"LANP\", \"PUMA\", \"POBP\"]:\n",
    "        if cat_col in df.columns:\n",
    "            df[cat_col] = df[cat_col].astype(\"string\")\n",
    "\n",
    "    #preserve leading zeros for categoricals\n",
    "    if \"PUMA\" in df.columns:\n",
    "        df[\"PUMA\"] = df[\"PUMA\"].str.zfill(5)\n",
    "\n",
    "    if \"OCCP\" in df.columns:\n",
    "        mask = df[\"OCCP\"].str.fullmatch(r\"\\d+\")\n",
    "        df.loc[mask, \"OCCP\"] = df.loc[mask, \"OCCP\"].str.zfill(4)\n",
    "\n",
    "    if \"POBP\" in df.columns:\n",
    "        df[\"POBP\"] = df[\"POBP\"].str.zfill(3)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce2631fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done preprocessing.\n"
     ]
    }
   ],
   "source": [
    "df_train_pp = preprocess_acs_data_rf(df_train)\n",
    "df_test_pp  = preprocess_acs_data_rf(df_test)\n",
    "\n",
    "print(\"Done preprocessing.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25f73028-c322-483f-85f8-2d09307919e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENG dtype: string\n",
      "Share ENG == '0.0' among LANX == 0: 1.0\n",
      "\n",
      "Value counts:\n",
      "ENG\n",
      "0.0    846170\n",
      "Name: count, dtype: Int64\n"
     ]
    }
   ],
   "source": [
    "#CHECK #1 (corrected for string ENG)\n",
    "sub = df_train_pp.loc[df_train_pp[\"LANX\"] == 0, \"ENG\"].astype(\"string\")\n",
    "\n",
    "print(\"ENG dtype:\", sub.dtype)\n",
    "print(\"Share ENG == '0.0' among LANX == 0:\", (sub == \"0.0\").mean())\n",
    "print(\"\\nValue counts:\")\n",
    "print(sub.value_counts(dropna=False).head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f51701",
   "metadata": {},
   "source": [
    "## 3) Feature set (expanded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc2255a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train raw: (1469769, 23) X_test raw: (304368, 23)\n"
     ]
    }
   ],
   "source": [
    "features = [\n",
    "    # numeric-ish\n",
    "    \"AGEP\", \"WKHP\", \"SCHL_Tier\",\n",
    "\n",
    "    # binaries\n",
    "    \"SEX\", \"DIS\", \"CIT\", \"MAR\", \"WRK\", \"Born_in_CA\", \"LANX\", \"ForeignBorn\", \"ESR_emp\", \"MIG_recent\",\n",
    "\n",
    "    # categoricals\n",
    "    \"MSP\", \"WKL\", \"ENG\", \"LANP\",\n",
    "    \"OCCP\", \"RAC1P\", \"CA_Region\",\n",
    "    \"PUMA\", \"POBP\",\n",
    "    \"year\"\n",
    "]\n",
    "\n",
    "target_col = \"poverty_risk_score\"\n",
    "\n",
    "missing = [c for c in features + [target_col] if c not in df_train_pp.columns]\n",
    "if missing:\n",
    "    print(\"WARNING missing columns:\", missing)\n",
    "\n",
    "# split for ColumnTransformer\n",
    "num_features = [\"AGEP\", \"WKHP\", \"SCHL_Tier\"]\n",
    "bin_features = [\"SEX\",\"DIS\",\"CIT\",\"MAR\",\"WRK\",\"Born_in_CA\",\"LANX\",\"ForeignBorn\",\"ESR_emp\",\"MIG_recent\"]\n",
    "cat_features = [\"MSP\",\"WKL\",\"ENG\",\"LANP\",\"OCCP\",\"RAC1P\",\"CA_Region\",\"PUMA\",\"POBP\",\"year\"]\n",
    "\n",
    "X_train = df_train_pp[features].copy()\n",
    "X_test  = df_test_pp[features].copy()\n",
    "y_train = df_train_pp[target_col].astype(int)\n",
    "y_test  = df_test_pp[target_col].astype(int)\n",
    "\n",
    "print(\"X_train raw:\", X_train.shape, \"X_test raw:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94daaae",
   "metadata": {},
   "source": [
    "## 4) Fix pandas nullable missing + build sparse preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ddbd654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_sparse: (1469769, 1266) <class 'scipy.sparse._csr.csr_matrix'>\n",
      "X_test_sparse : (304368, 1266) <class 'scipy.sparse._csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "# Make numerics real numeric and categoricals plain objects with None for missing.\n",
    "\n",
    "for c in num_features + bin_features:\n",
    "    X_train[c] = pd.to_numeric(X_train[c], errors=\"coerce\")\n",
    "    X_test[c]  = pd.to_numeric(X_test[c], errors=\"coerce\")\n",
    "\n",
    "for c in cat_features:\n",
    "    X_train[c] = X_train[c].astype(\"object\")\n",
    "    X_test[c]  = X_test[c].astype(\"object\")\n",
    "    X_train[c] = X_train[c].where(pd.notna(X_train[c]), None)\n",
    "    X_test[c]  = X_test[c].where(pd.notna(X_test[c]), None)\n",
    "\n",
    "# Bucket rare categories into an 'infrequent' bin to keep feature space manageable.\n",
    "MIN_FREQ = 25  # can alter this value for runtime: 5/25/50 \n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", SimpleImputer(strategy=\"median\"), num_features),\n",
    "        (\"bin\", SimpleImputer(strategy=\"most_frequent\"), bin_features),\n",
    "        (\"cat\", Pipeline(steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"ohe\", OneHotEncoder(\n",
    "                handle_unknown=\"ignore\",\n",
    "                sparse_output=True,\n",
    "                min_frequency=MIN_FREQ\n",
    "            ))\n",
    "        ]), cat_features),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "X_train_sparse = preprocess.fit_transform(X_train)\n",
    "X_test_sparse  = preprocess.transform(X_test)\n",
    "\n",
    "print(\"X_train_sparse:\", X_train_sparse.shape, type(X_train_sparse))\n",
    "print(\"X_test_sparse :\", X_test_sparse.shape, type(X_test_sparse))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ed695b-19e0-49e8-a9f4-ddcac6d1b6da",
   "metadata": {},
   "source": [
    "## 5) Save Sparse matrices/labels/preprocesser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c011619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete. Files saved to preprocessing_data/\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from scipy import sparse\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure directory exists\n",
    "output_dir = Path(\"preprocessing_data\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save sparse matrices\n",
    "sparse.save_npz(output_dir / \"X_train_sparse_rf.npz\", X_train_sparse)\n",
    "sparse.save_npz(output_dir / \"X_test_sparse_rf.npz\", X_test_sparse)\n",
    "\n",
    "# Save labels\n",
    "y_train.to_csv(output_dir / \"y_train_rf.csv\", index=False)\n",
    "y_test.to_csv(output_dir / \"y_test_rf.csv\", index=False)\n",
    "\n",
    "# Save fitted preprocessor\n",
    "joblib.dump(preprocess, output_dir / \"rf_preprocessor.joblib\")\n",
    "\n",
    "print(\"Preprocessing complete. Files saved to preprocessing_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d14174-e0ee-463a-92f9-9eec49d56e53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
